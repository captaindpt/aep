‹¢idÙ@39af0432dd2aa682cee0ef1dc34325cf3a6537f9a4f668d70a5fa6dda8a1990d¢tsËAÚş.©İ©¨trace_id¤Q000­parent_run_idÀ¦run_idÙ$02bfec5c-0137-45b2-8f12-b618d51e9496ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ)What is LangChain and why was it created?¨query_id¤Q000§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q000ªfocus_kind¯chain_execution‹¢idÙ@5a08d4979240fa2236b385cc3a04231517e8759e5f619a52c0412dfff3d24a0a¢tsËAÚş.©ò¦¨trace_id¤Q000­parent_run_idÙ$02bfec5c-0137-45b2-8f12-b618d51e9496¦run_idÙ$78d8cae0-4583-4a10-94db-9c1656f1ff57ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ)What is LangChain and why was it created?§context¦answer ¨query_id¤Q000¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q000®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:6a082f33-2a89-fa88-fcd9-af6b8e8b36b8ªfocus_kind¯chain_execution‰¢idÙ@6e41a001efd3e393c8992b454de39f01422f5f24fdac8859a60e87d0463078ab¢tsËAÚş.¼P¨trace_idÙ$3a841046-3e3c-428f-84cf-be2db2a4b30e­parent_run_idÙ$02bfec5c-0137-45b2-8f12-b618d51e9496¦run_idÙ$3a841046-3e3c-428f-84cf-be2db2a4b30eªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Why LangChain?

The goal of `langchain` the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.
While LangChain originally st...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx‚´page_content_summaryÙË## Features

There are several primary needs that LangChain aims to address:

1. **Standardized component interfaces:** The growing number of [models](/docs/integrations/chat/) and [related components...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx‚´page_content_summaryÙË---
sidebar_position: 0
sidebar_class_name: hidden
---

# Introduction

**LangChain** is a framework for developing applications powered by large language models (LLMs).

LangChain simplifies every st...¨metadata¦sourceÙB/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/introduction.mdx¨query_id¤Q000¨questionÙ)What is LangChain and why was it created?ªfocus_kind¶chain_execution_result‹¢idÙ@d47c91441a5e0189935eacb0cfe00711970d4802d464c4d0291e88f4100730c1¢tsËAÚş.¼"S¨trace_id¤Q000­parent_run_idÙ$797d7cbf-9378-4d04-bb19-c9d077d8ef9c¦run_idÙ$1a1b5912-e0ae-4945-9f5f-9cfe4364f178ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ)What is LangChain and why was it created?§contextÚ×# Why LangChain?

The goal of `langchain` the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.
While LangChain originally started as a single open source package, it has evolved into a company and a whole ecosystem.
This page will talk about the LangChain ecosystem as a whole.
Most of the components within the LangChain ecosystem can be used by themselves - so if you feel particularly drawn to certain components but not others, that is totally fine! Pick and choose whichever components you like best for your own use case!

## Features

There are several primary needs that LangChain aims to address:

## Features

There are several primary needs that LangChain aims to address:

1. **Standardized component interfaces:** The growing number of [models](/docs/integrations/chat/) and [related components](/docs/integrations/vectorstores/) for AI applications has resulted in a wide variety of different APIs that developers need to learn and use.
This diversity can make it challenging for developers to switch between providers or combine components when building applications.
LangChain exposes a standard interface for key components, making it easy to switch between providers.

---
sidebar_position: 0
sidebar_class_name: hidden
---

# Introduction

**LangChain** is a framework for developing applications powered by large language models (LLMs).

LangChain simplifies every stage of the LLM application lifecycle:
- **Development**: Build your applications using LangChain's open-source [components](/docs/concepts) and [third-party integrations](/docs/integrations/providers/).
Use [LangGraph](/docs/concepts/architecture/#langgraph) to build stateful agents with first-class streaming and human-in-the-loop support.
- **Productionization**: Use [LangSmith](https://docs.smith.langchain.com/) to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.
- **Deployment**: Turn your LangGraph applications into production-ready APIs and Assistants with [LangGraph Platform](https://langchain-ai.github.io/langgraph/cloud/).

import ThemedImage from '@theme/ThemedImage';
import useBaseUrl from '@docusaurus/useBaseUrl';¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q000®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:63a746c9-25a8-5c4e-d828-e61e3aa81f46­checkpoint_nsÙ-generate:63a746c9-25a8-5c4e-d828-e61e3aa81f46¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@a1cd05d8850fffd89c151925f52b014d1859b164f0f3c5b7ccc8e4e4f2427337¢tsËAÚş.¼)Ğ¨trace_idÙ$1a1b5912-e0ae-4945-9f5f-9cfe4364f178­parent_run_idÙ$797d7cbf-9378-4d04-bb19-c9d077d8ef9c¦run_idÙ$1a1b5912-e0ae-4945-9f5f-9cfe4364f178ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚ
messages=[HumanMessage(content="You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: What is LangChain and why was it created? \nContext: # Why LangChain?\n\nThe goal of `langchain` the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.\nWhile LangChain originally started as a single open source package, it has evolved into a company and a whole ecosystem.\nThis page will talk about the LangChain ecosystem as a whole.\nMost of the components within the LangChain ecosystem can be used by themselves - so if you feel particularly drawn to certain components but not others, that is totally fine! Pick and choose whichever components you like best for your own use case!\n\n## Features\n\nThere are several primary needs that LangChain aims to address:\n\n## Features\n\nThere are several primary needs that LangChain aims to address:\n\n1. **Standardized component interfaces:** The growing number of [models](/docs/integrations/chat/) and [related components](/docs/integrations/vectorstores/) for AI applications has resulted in a wide variety of different APIs that developers need to learn and use.\nThis diversity can make it challenging for developers to switch between providers or combine components when building applications.\nLangChain exposes a standard interface for key components, making it easy to switch between providers.\n\n---\nsidebar_position: 0\nsidebar_class_name: hidden\n---\n\n# Introduction\n\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\n\nLangChain simplifies every stage of the LLM application lifecycle:\n- **Development**: Build your applications using LangChain's open-source [components](/docs/concepts) and [third-party integrations](/docs/integrations/providers/).\nUse [LangGraph](/docs/concepts/architecture/#langgraph) to build stateful agents with first-class streaming and human-in-the-loop support.\n- **Productionization**: Use [LangSmith](https://docs.smith.langchain.com/) to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\n- **Deployment**: Turn your LangGraph applications into production-ready APIs and Assistants with [LangGraph Platform](https://langchain-ai.github.io/langgraph/cloud/).\n\nimport ThemedImage from '@theme/ThemedImage';\nimport useBaseUrl from '@docusaurus/useBaseUrl'; \nAnswer:", additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@471d732de487c497bcc0b2892e8627d4bf1c3557958ee07eacd2fcc06b47ba18¢tsËAÚş/Ôí¨focus_msÍi§payload‚¤role©assistant§contentÚ’LangChain is a framework designed to help developers build applications powered by large language models (LLMs) more easily. It was created to standardize component interfaces, making it simpler for developers to switch between different providers and combine various components in their applications. Originally an open-source package, LangChain has evolved into a comprehensive ecosystem and company.ªfocus_kind¬exec_latency¨query_id¤Q000‰¢idÙ@367b8e9516dfcc1241b757deecd688a11b4902292ce0343cd200d70395047b00¢tsËAÚş/çï¨trace_idÙ$797d7cbf-9378-4d04-bb19-c9d077d8ef9c­parent_run_idÙ$02bfec5c-0137-45b2-8f12-b618d51e9496¦run_idÙ$797d7cbf-9378-4d04-bb19-c9d077d8ef9cªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ’LangChain is a framework designed to help developers build applications powered by large language models (LLMs) more easily. It was created to standardize component interfaces, making it simpler for developers to switch between different providers and combine various components in their applications. Originally an open-source package, LangChain has evolved into a comprehensive ecosystem and company.¨query_id¤Q000ªfocus_kind¶chain_execution_result‹¢idÙ@e218eed8a966c597babb971d6269ac258f6542fde939c884b3719c6a87dd63a5¢tsËAÚş/Â¨trace_id¤Q001­parent_run_idÀ¦run_idÙ$4e98af2f-1f6e-420d-b8cf-0d3432d622a8ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ*Explain the role of an Agent in LangChain.¨query_id¤Q001§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q001ªfocus_kind¯chain_execution‹¢idÙ@1d8200206d8ed109cad2bb040877a64c08e5076e43fc827b0ee6e71239b23117¢tsËAÚş/+í¨trace_id¤Q001­parent_run_idÙ$4e98af2f-1f6e-420d-b8cf-0d3432d622a8¦run_idÙ$dac7355a-cba1-4942-b403-e3043e26ba10ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ*Explain the role of an Agent in LangChain.§context¦answer ¨query_id¤Q001¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q001®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:da5744cb-13d7-8885-2b45-903bc29ba067ªfocus_kind¯chain_execution‰¢idÙ@adbab92d5db2e8181e75d92a4068631ba86c002f2a4386f3c9841f2d9e1177c2¢tsËAÚş/,†¨trace_idÙ$03cf37ec-1645-4fe2-b7c8-5fb37c3cdac6­parent_run_idÙ$4e98af2f-1f6e-420d-b8cf-0d3432d622a8¦run_idÙ$03cf37ec-1645-4fe2-b7c8-5fb37c3cdac6ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Agents

By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take ...¨metadata¦sourceÙE/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/agents.mdx‚´page_content_summaryÙË## Legacy agent concept: AgentExecutor

LangChain previously introduced the `AgentExecutor` as a runtime for agents. 
While it served as an excellent starting point, its limitations became apparent wh...¨metadata¦sourceÙE/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/agents.mdx‚´page_content_summaryÙË[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like incl...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx¨query_id¤Q001¨questionÙ*Explain the role of an Agent in LangChain.ªfocus_kind¶chain_execution_result‹¢idÙ@03353f3476f198acfc7b7dff612b7f5207197feeb75a5b51a4177f2d45ecbd03¢tsËAÚş/,¤”¨trace_id¤Q001­parent_run_idÙ$da1dda28-f517-406d-9918-a6cef12d9c51¦run_idÙ$9c97f4b0-d5e2-4b34-950a-1f666a607bddªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ*Explain the role of an Agent in LangChain.§contextÚ	\# Agents

By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.

[LangGraph](/docs/concepts/architecture#langgraph) is an extension of LangChain specifically aimed at creating highly controllable and customizable agents. We recommend that you use LangGraph for building agents.

Please see the following resources for more information:

* LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
* [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)

## Legacy agent concept: AgentExecutor

## Legacy agent concept: AgentExecutor

LangChain previously introduced the `AgentExecutor` as a runtime for agents. 
While it served as an excellent starting point, its limitations became apparent when dealing with more sophisticated and customized agents. 
As a result, we're gradually phasing out `AgentExecutor` in favor of more flexible solutions in LangGraph.

### Transitioning from AgentExecutor to langgraph

If you're currently using `AgentExecutor`, don't worry! We've prepared resources to help you:

1. For those who still need to use `AgentExecutor`, we offer a comprehensive guide on [how to use AgentExecutor](/docs/how_to/agent_executor).

2. However, we strongly recommend transitioning to LangGraph for improved flexibility and control. To facilitate this transition, we've created a detailed [migration guide](/docs/how_to/migrate_agent) to help you move from `AgentExecutor` to LangGraph seamlessly.

[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like including [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/), [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/), or [memory](https://langchain-ai.github.io/langgraph/concepts/memory/).

[LangSmith](https://docs.smith.langchain.com/) makes it possible to iterate with confidence on your applications, by providing LLM-specific observability and framework for testing and evaluating your application.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q001®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:de8fd761-fe23-aed1-827a-231fae5b81fc­checkpoint_nsÙ-generate:de8fd761-fe23-aed1-827a-231fae5b81fc¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@8ca09b3b5dc2829e4cc62a7ce77e259765bd908741750d05ab2206ab17f75f30¢tsËAÚş/,¬m¨trace_idÙ$9c97f4b0-d5e2-4b34-950a-1f666a607bdd­parent_run_idÙ$da1dda28-f517-406d-9918-a6cef12d9c51¦run_idÙ$9c97f4b0-d5e2-4b34-950a-1f666a607bddªevent_type¬chain_output¬event_source¥chain§payload§outputsÚmessages=[HumanMessage(content="You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Explain the role of an Agent in LangChain. \nContext: # Agents\n\nBy themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.\n\n[LangGraph](/docs/concepts/architecture#langgraph) is an extension of LangChain specifically aimed at creating highly controllable and customizable agents. We recommend that you use LangGraph for building agents.\n\nPlease see the following resources for more information:\n\n* LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\n* [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)\n\n## Legacy agent concept: AgentExecutor\n\n## Legacy agent concept: AgentExecutor\n\nLangChain previously introduced the `AgentExecutor` as a runtime for agents. \nWhile it served as an excellent starting point, its limitations became apparent when dealing with more sophisticated and customized agents. \nAs a result, we're gradually phasing out `AgentExecutor` in favor of more flexible solutions in LangGraph.\n\n### Transitioning from AgentExecutor to langgraph\n\nIf you're currently using `AgentExecutor`, don't worry! We've prepared resources to help you:\n\n1. For those who still need to use `AgentExecutor`, we offer a comprehensive guide on [how to use AgentExecutor](/docs/how_to/agent_executor).\n\n2. However, we strongly recommend transitioning to LangGraph for improved flexibility and control. To facilitate this transition, we've created a detailed [migration guide](/docs/how_to/migrate_agent) to help you move from `AgentExecutor` to LangGraph seamlessly.\n\n[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like including [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/), [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/), or [memory](https://langchain-ai.github.io/langgraph/concepts/memory/).\n\n[LangSmith](https://docs.smith.langchain.com/) makes it possible to iterate with confidence on your applications, by providing LLM-specific observability and framework for testing and evaluating your application. \nAnswer:", additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@f62f60e4f7794c57d6e94528809016e40f80ea452fc27414d7bf949acef24a75¢tsËAÚş/§‹ï¨focus_msÍ§payload‚¤role©assistant§contentÚ–In LangChain, an Agent acts as a system that takes a high-level task and utilizes a language model (LLM) as a reasoning engine to determine and execute the necessary actions. LangGraph is the recommended framework for building these agents, offering enhanced control and customization. The previous `AgentExecutor` concept is being phased out in favor of LangGraph for more sophisticated agent development.ªfocus_kind¬exec_latency¨query_id¤Q001‰¢idÙ@16b462da78e00bf229473d2a42e414a9f1baf37f86dde3b51ec033aca3fcebde¢tsËAÚş/§™å¨trace_idÙ$da1dda28-f517-406d-9918-a6cef12d9c51­parent_run_idÙ$4e98af2f-1f6e-420d-b8cf-0d3432d622a8¦run_idÙ$da1dda28-f517-406d-9918-a6cef12d9c51ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ–In LangChain, an Agent acts as a system that takes a high-level task and utilizes a language model (LLM) as a reasoning engine to determine and execute the necessary actions. LangGraph is the recommended framework for building these agents, offering enhanced control and customization. The previous `AgentExecutor` concept is being phased out in favor of LangGraph for more sophisticated agent development.¨query_id¤Q001ªfocus_kind¶chain_execution_result‹¢idÙ@0a26322b3329e54f7cf804d1d1f085ff701411db1620b64a3c7dc67d241402f7¢tsËAÚş/§Õ¢¨trace_id¤Q002­parent_run_idÀ¦run_idÙ$4843933a-e725-446c-b4f9-e6a669da9c38ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3How do I install LangChain with extras for tracing?¨query_id¤Q002§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q002ªfocus_kind¯chain_execution‹¢idÙ@909398fd1922449bf4ab382c31a00fdd8a1044e8e3154bd86905c2d65771b1bd¢tsËAÚş/§äï¨trace_id¤Q002­parent_run_idÙ$4843933a-e725-446c-b4f9-e6a669da9c38¦run_idÙ$df4c1ba2-79c5-4927-a356-df77abe46728ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3How do I install LangChain with extras for tracing?§context¦answer ¨query_id¤Q002¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q002®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:bcae76c0-f162-e0da-872d-e14fad903aedªfocus_kind¯chain_execution‰¢idÙ@eb273ad3085b8d1bde6222ffe5895fee3e7b4ec57c2a6adaa80487c65a1ca072¢tsËAÚş/Á<Ä¨trace_idÙ$1c192279-5583-4ec2-9f3d-589a1559b617­parent_run_idÙ$4843933a-e725-446c-b4f9-e6a669da9c38¦run_idÙ$1c192279-5583-4ec2-9f3d-589a1559b617ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙÀ```bash
pip install -e .
```

LangGraph, LangSmith SDK, and certain integration packages live outside the main LangChain repo. You can see [all repos here](https://github.com/langchain-ai)....¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/installation.mdx‚´page_content_summaryÙË## Compatibility

LangChain is only compatible with the `asyncio` library, which is distributed as part of the Python standard library. It will not work with other async libraries like `trio` or `curi...¨metadata¦sourceÙD/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/async.mdx‚´page_content_summaryÙË---
sidebar_position: 2
---

# How to install LangChain packages

The LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of
functionality to install.
...¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/installation.mdx¨query_id¤Q002¨questionÙ3How do I install LangChain with extras for tracing?ªfocus_kind¶chain_execution_result‹¢idÙ@0e11727b78f1b2d878adb58f703a08389c2e5a640408c9c15ee3b1aa0f0c0f95¢tsËAÚş/ÁIY¨trace_id¤Q002­parent_run_idÙ$3b8c4ba9-bce3-4e09-a543-cc06f2012c4f¦run_idÙ$a4f3ca20-d2b7-49dd-9fd2-51332658a706ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ3How do I install LangChain with extras for tracing?§contextÚC```bash
pip install -e .
```

LangGraph, LangSmith SDK, and certain integration packages live outside the main LangChain repo. You can see [all repos here](https://github.com/langchain-ai).

## Compatibility

LangChain is only compatible with the `asyncio` library, which is distributed as part of the Python standard library. It will not work with other async libraries like `trio` or `curio`.

In Python 3.9 and 3.10, [asyncio's tasks](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task) did not
accept a `context` parameter. Due to this limitation, LangChain cannot automatically propagate the `RunnableConfig` down the call chain
in certain scenarios.

If you are experiencing issues with streaming, callbacks or tracing in async code and are using Python 3.9 or 3.10, this is a likely cause.

Please read [Propagation RunnableConfig](/docs/concepts/runnables/#propagation-of-runnableconfig) for more details to learn how to propagate the `RunnableConfig` down the call chain manually (or upgrade to Python 3.11 where this is no longer an issue).

## How to use in ipython and jupyter notebooks

---
sidebar_position: 2
---

# How to install LangChain packages

The LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of
functionality to install.

## Official release

To install the main `langchain` package, run:

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from "@theme/CodeBlock";

<Tabs>
  <TabItem value="pip" label="Pip" default>
    <CodeBlock language="bash">pip install langchain</CodeBlock>
  </TabItem>
  <TabItem value="conda" label="Conda">
    <CodeBlock language="bash">conda install langchain -c conda-forge</CodeBlock>
  </TabItem>
</Tabs>

While this package acts as a sane starting point to using LangChain,
much of the value of LangChain comes when integrating it with various model providers, datastores, etc.
By default, the dependencies needed to do that are NOT installed. You will need to install the dependencies for specific integrations separately, which we show below.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q002®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:2c2ceb03-d1e8-02c0-14a2-e3d281327059­checkpoint_nsÙ-generate:2c2ceb03-d1e8-02c0-14a2-e3d281327059¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@b670dd0382af88165eb5ce3dbc6075eb43955fc6d3874515545876aa29be5d77¢tsËAÚş/ÁRç¨trace_idÙ$a4f3ca20-d2b7-49dd-9fd2-51332658a706­parent_run_idÙ$3b8c4ba9-bce3-4e09-a543-cc06f2012c4f¦run_idÙ$a4f3ca20-d2b7-49dd-9fd2-51332658a706ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚ
messages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: How do I install LangChain with extras for tracing? \nContext: ```bash\npip install -e .\n```\n\nLangGraph, LangSmith SDK, and certain integration packages live outside the main LangChain repo. You can see [all repos here](https://github.com/langchain-ai).\n\n## Compatibility\n\nLangChain is only compatible with the `asyncio` library, which is distributed as part of the Python standard library. It will not work with other async libraries like `trio` or `curio`.\n\nIn Python 3.9 and 3.10, [asyncio\'s tasks](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task) did not\naccept a `context` parameter. Due to this limitation, LangChain cannot automatically propagate the `RunnableConfig` down the call chain\nin certain scenarios.\n\nIf you are experiencing issues with streaming, callbacks or tracing in async code and are using Python 3.9 or 3.10, this is a likely cause.\n\nPlease read [Propagation RunnableConfig](/docs/concepts/runnables/#propagation-of-runnableconfig) for more details to learn how to propagate the `RunnableConfig` down the call chain manually (or upgrade to Python 3.11 where this is no longer an issue).\n\n## How to use in ipython and jupyter notebooks\n\n---\nsidebar_position: 2\n---\n\n# How to install LangChain packages\n\nThe LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of\nfunctionality to install.\n\n## Official release\n\nTo install the main `langchain` package, run:\n\nimport Tabs from \'@theme/Tabs\';\nimport TabItem from \'@theme/TabItem\';\nimport CodeBlock from "@theme/CodeBlock";\n\n<Tabs>\n  <TabItem value="pip" label="Pip" default>\n    <CodeBlock language="bash">pip install langchain</CodeBlock>\n  </TabItem>\n  <TabItem value="conda" label="Conda">\n    <CodeBlock language="bash">conda install langchain -c conda-forge</CodeBlock>\n  </TabItem>\n</Tabs>\n\nWhile this package acts as a sane starting point to using LangChain,\nmuch of the value of LangChain comes when integrating it with various model providers, datastores, etc.\nBy default, the dependencies needed to do that are NOT installed. You will need to install the dependencies for specific integrations separately, which we show below. \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@0b7024d81aeadf304b06868c40257a26486d515c3fb1e724c3fd229313f80457¢tsËAÚş07@–¨focus_msÍ2§payload‚¤role©assistant§contentÚTo install LangChain with extras for tracing, you can use the command `pip install langchain[tracing]`. This will install the main LangChain package along with the additional dependencies required for tracing functionality. Make sure to check the specific integration packages if needed.ªfocus_kind¬exec_latency¨query_id¤Q002‰¢idÙ@49b44734d374d2e42ab60125abeb2ff218df3a15e09257c619ebe55d00d765e3¢tsËAÚş07J¨trace_idÙ$3b8c4ba9-bce3-4e09-a543-cc06f2012c4f­parent_run_idÙ$4843933a-e725-446c-b4f9-e6a669da9c38¦run_idÙ$3b8c4ba9-bce3-4e09-a543-cc06f2012c4fªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚTo install LangChain with extras for tracing, you can use the command `pip install langchain[tracing]`. This will install the main LangChain package along with the additional dependencies required for tracing functionality. Make sure to check the specific integration packages if needed.¨query_id¤Q002ªfocus_kind¶chain_execution_result‹¢idÙ@31a09566aaab0b6ffbf4b6a382f60956eab560042f4d0c590ab66afb8e7ba021¢tsËAÚş07R—¨trace_id¤Q003­parent_run_idÀ¦run_idÙ$a57f3471-b1ed-492e-9559-e488fd640ff8ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ8Show the minimal LCEL chain that streams token-by-token.¨query_id¤Q003§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q003ªfocus_kind¯chain_execution‹¢idÙ@8470a10e17e5cb365e2e201c091d32410a70be39250269e56c153f6ed34d9212¢tsËAÚş07Z¨trace_id¤Q003­parent_run_idÙ$a57f3471-b1ed-492e-9559-e488fd640ff8¦run_idÙ$f7b01cda-a7bc-4316-a225-37198507e1edªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ8Show the minimal LCEL chain that streams token-by-token.§context¦answer ¨query_id¤Q003¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q003®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:28af6abd-ecc0-516a-f590-b7c4281df98bªfocus_kind¯chain_execution‰¢idÙ@7d5ac96f071a068c7b7275aee479b3aee8caddae6bc1372bee921a2ce1da2edf¢tsËAÚş0I£e¨trace_idÙ$b72a9a3e-b543-45e7-805e-33f0869a6722­parent_run_idÙ$a57f3471-b1ed-492e-9559-e488fd640ff8¦run_idÙ$b72a9a3e-b543-45e7-805e-33f0869a6722ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË- **Simplify streaming**: LCEL chains can be streamed, allowing for incremental output as the chain is executed. LangChain can optimize the streaming of the output to minimize the time-to-first-token(...¨metadata¦sourceÙC/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/lcel.mdx‚´page_content_summaryÙËFor chains constructed using **LCEL**, the `.stream()` method only streams the output of the final step from the chain. This might be sufficient for some applications, but as you build more complex ch...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/streaming.mdx‚´page_content_summaryÙË# LangChain Expression Language (LCEL)

:::info Prerequisites
* [Runnable Interface](/docs/concepts/runnables)
:::

The **L**ang**C**hain **E**xpression **L**anguage (LCEL) takes a [declarative](https...¨metadata¦sourceÙC/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/lcel.mdx¨query_id¤Q003¨questionÙ8Show the minimal LCEL chain that streams token-by-token.ªfocus_kind¶chain_execution_result‹¢idÙ@7b4ff95b35a0e50e0e38d76384419cee8cb32e15c5fee71b57dd9ee4a0ce4890¢tsËAÚş0I¯Å¨trace_id¤Q003­parent_run_idÙ$70d38187-a3b5-4d1b-adcb-04da37f60d6b¦run_idÙ$05cf0178-9af8-4e89-aea8-02e427c4577aªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ8Show the minimal LCEL chain that streams token-by-token.§contextÚ½- **Simplify streaming**: LCEL chains can be streamed, allowing for incremental output as the chain is executed. LangChain can optimize the streaming of the output to minimize the time-to-first-token(time elapsed until the first chunk of output from a [chat model](/docs/concepts/chat_models) or [llm](/docs/concepts/text_llms) comes out).

For chains constructed using **LCEL**, the `.stream()` method only streams the output of the final step from the chain. This might be sufficient for some applications, but as you build more complex chains of several LLM calls together, you may want to use the intermediate values of the chain alongside the final output. For example, you may want to return sources alongside the final generation when building a chat-over-documents app.

# LangChain Expression Language (LCEL)

:::info Prerequisites
* [Runnable Interface](/docs/concepts/runnables)
:::

The **L**ang**C**hain **E**xpression **L**anguage (LCEL) takes a [declarative](https://en.wikipedia.org/wiki/Declarative_programming) approach to building new [Runnables](/docs/concepts/runnables) from existing Runnables.

This means that you describe what *should* happen, rather than *how* it should happen, allowing LangChain to optimize the run-time execution of the chains.

We often refer to a `Runnable` created using LCEL as a "chain". It's important to remember that a "chain" is `Runnable` and it implements the full [Runnable Interface](/docs/concepts/runnables).¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q003®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:dbe77e61-9f13-8a21-237a-1b0079280aea­checkpoint_nsÙ-generate:dbe77e61-9f13-8a21-237a-1b0079280aea¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@eaa7be496601c28dca9c7bbb257a77dddf7ae00d877fef8cab534fd6b8c38091¢tsËAÚş0I¶î¨trace_idÙ$05cf0178-9af8-4e89-aea8-02e427c4577a­parent_run_idÙ$70d38187-a3b5-4d1b-adcb-04da37f60d6b¦run_idÙ$05cf0178-9af8-4e89-aea8-02e427c4577aªevent_type¬chain_output¬event_source¥chain§payload§outputsÚdmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Show the minimal LCEL chain that streams token-by-token. \nContext: - **Simplify streaming**: LCEL chains can be streamed, allowing for incremental output as the chain is executed. LangChain can optimize the streaming of the output to minimize the time-to-first-token(time elapsed until the first chunk of output from a [chat model](/docs/concepts/chat_models) or [llm](/docs/concepts/text_llms) comes out).\n\nFor chains constructed using **LCEL**, the `.stream()` method only streams the output of the final step from the chain. This might be sufficient for some applications, but as you build more complex chains of several LLM calls together, you may want to use the intermediate values of the chain alongside the final output. For example, you may want to return sources alongside the final generation when building a chat-over-documents app.\n\n# LangChain Expression Language (LCEL)\n\n:::info Prerequisites\n* [Runnable Interface](/docs/concepts/runnables)\n:::\n\nThe **L**ang**C**hain **E**xpression **L**anguage (LCEL) takes a [declarative](https://en.wikipedia.org/wiki/Declarative_programming) approach to building new [Runnables](/docs/concepts/runnables) from existing Runnables.\n\nThis means that you describe what *should* happen, rather than *how* it should happen, allowing LangChain to optimize the run-time execution of the chains.\n\nWe often refer to a `Runnable` created using LCEL as a "chain". It\'s important to remember that a "chain" is `Runnable` and it implements the full [Runnable Interface](/docs/concepts/runnables). \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@338ebbea69f6d8f3b6212c6b4db425293bc22a01cae2d924a93f3ff04e085461¢tsËAÚş0sæ¨focus_msÍ§payload‚¤role©assistant§contentÚeThe minimal LCEL chain that streams token-by-token can be constructed using the `.stream()` method, which streams the output of the final step in the chain. This allows for incremental output as the chain executes, optimizing the time-to-first-token. For more complex applications, you may want to incorporate intermediate values alongside the final output.ªfocus_kind¬exec_latency¨query_id¤Q003‰¢idÙ@ec825d648d29ac2265dc5f620b5235a6be5ada0f46ea262c6a10d58640e77d81¢tsËAÚş0€0¨trace_idÙ$70d38187-a3b5-4d1b-adcb-04da37f60d6b­parent_run_idÙ$a57f3471-b1ed-492e-9559-e488fd640ff8¦run_idÙ$70d38187-a3b5-4d1b-adcb-04da37f60d6bªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚeThe minimal LCEL chain that streams token-by-token can be constructed using the `.stream()` method, which streams the output of the final step in the chain. This allows for incremental output as the chain executes, optimizing the time-to-first-token. For more complex applications, you may want to incorporate intermediate values alongside the final output.¨query_id¤Q003ªfocus_kind¶chain_execution_result‹¢idÙ@df7011666b6f4ed211c85a5a3d224bd6359af6feb688144cb01a88471f6327ef¢tsËAÚş0ˆ¹¨trace_id¤Q004­parent_run_idÀ¦run_idÙ$55094f6a-3064-4349-8fa4-f414d80003ffªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.¨query_id¤Q004§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q004ªfocus_kind¯chain_execution‹¢idÙ@8c4ec4be97000c9dd7a2c04fd9c43bf8388c76a72eca4a01dc1c4a7dd8f24992¢tsËAÚş0”y¨trace_id¤Q004­parent_run_idÙ$55094f6a-3064-4349-8fa4-f414d80003ff¦run_idÙ$1979041d-8367-4426-adbe-dcc0add5e5b5ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.§context¦answer ¨query_id¤Q004¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q004®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:37e123d6-dc9f-9e2d-628d-85a95271a5c9ªfocus_kind¯chain_execution‰¢idÙ@b62830e86e807e77b655128f36e495ba1a056ab88c83a389436de79ef4e14aa2¢tsËAÚş0©]¨trace_idÙ$4be75541-96b6-4051-938f-4caa48551d20­parent_run_idÙ$55094f6a-3064-4349-8fa4-f414d80003ff¦run_idÙ$4be75541-96b6-4051-938f-4caa48551d20ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙËThere are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.


<Tabs>
  <TabIt...¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/vectorstores.mdx‚´page_content_summaryÙË:::

### Similarity search

Given a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over *all* the embedded d...¨metadata¦sourceÙK/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/vectorstores.mdx‚´page_content_summaryÙË```python
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="lance" label="Lance">

This notebook shows ho...¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/vectorstores.mdx¨query_id¤Q004¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.ªfocus_kind¶chain_execution_result‹¢idÙ@95bb9403a8c310b4402001f4393dc43a974a13ef555c94a6e91b86ec75546b2a¢tsËAÚş0©oç¨trace_id¤Q004­parent_run_idÙ$c8e4d0c8-2b15-4a22-8872-34940e020dc8¦run_idÙ$da8697a6-b1f5-4ef8-a55c-16bbd97fe3dbªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.§contextÚ
ØThere are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.


<Tabs>
  <TabItem value="chroma" label="Chroma" default>

This walkthrough uses the `chroma` vector database, which runs on your local machine as a library.

```bash
pip install langchain-chroma
```

```python
from langchain_chroma import Chroma

db = Chroma.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="faiss" label="FAISS">

This walkthrough uses the `FAISS` vector database, which makes use of the Facebook AI Similarity Search (FAISS) library.

```bash
pip install faiss-cpu
```

```python
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="lance" label="Lance">

:::

### Similarity search

Given a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over *all* the embedded documents to find the most similar ones.
There are various ways to do this. As an example, many vectorstores implement [HNSW (Hierarchical Navigable Small World)](https://www.pinecone.io/learn/series/faiss/hnsw/), a graph-based index structure that allows for efficient similarity search.
Regardless of the search algorithm used under the hood, the LangChain vectorstore interface has a `similarity_search` method for all integrations. 
This will take the search query, create an embedding, find similar documents, and return them as a list of [Documents](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html).

```python
query = "my query"
docs = vectorstore.similarity_search(query)
```

```python
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="lance" label="Lance">

This notebook shows how to use functionality related to the LanceDB vector database based on the Lance data format.

```bash
pip install lancedb
```

```python
from langchain_community.vectorstores import LanceDB

import lancedb

db = lancedb.connect("/tmp/lancedb")
table = db.create_table(
    "my_table",
    data=[
        {
            "vector": embeddings.embed_query("Hello World"),
            "text": "Hello World",
            "id": "1",
        }
    ],
    mode="overwrite",
)
db = LanceDB.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
</Tabs>


## Similarity search

All vectorstores expose a `similarity_search` method.
This will take incoming documents, create an embedding of them, and then find all documents with the most similar embedding.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q004®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:fdd59016-116b-9820-bdef-7cf28259a4d8­checkpoint_nsÙ-generate:fdd59016-116b-9820-bdef-7cf28259a4d8¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@fb3447faf7d05613e8061b44ec3e5be8f2e0c6d4e5e27b2ebb886dc12dac184a¢tsËAÚş0©{=¨trace_idÙ$da8697a6-b1f5-4ef8-a55c-16bbd97fe3db­parent_run_idÙ$c8e4d0c8-2b15-4a22-8872-34940e020dc8¦run_idÙ$da8697a6-b1f5-4ef8-a55c-16bbd97fe3dbªevent_type¬chain_output¬event_source¥chain§payload§outputsÚÈmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Compare FAISS and Chroma vector stores in LangChain. \nContext: There are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.\n\n\n<Tabs>\n  <TabItem value="chroma" label="Chroma" default>\n\nThis walkthrough uses the `chroma` vector database, which runs on your local machine as a library.\n\n```bash\npip install langchain-chroma\n```\n\n```python\nfrom langchain_chroma import Chroma\n\ndb = Chroma.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n  <TabItem value="faiss" label="FAISS">\n\nThis walkthrough uses the `FAISS` vector database, which makes use of the Facebook AI Similarity Search (FAISS) library.\n\n```bash\npip install faiss-cpu\n```\n\n```python\nfrom langchain_community.vectorstores import FAISS\n\ndb = FAISS.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n  <TabItem value="lance" label="Lance">\n\n:::\n\n### Similarity search\n\nGiven a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over *all* the embedded documents to find the most similar ones.\nThere are various ways to do this. As an example, many vectorstores implement [HNSW (Hierarchical Navigable Small World)](https://www.pinecone.io/learn/series/faiss/hnsw/), a graph-based index structure that allows for efficient similarity search.\nRegardless of the search algorithm used under the hood, the LangChain vectorstore interface has a `similarity_search` method for all integrations. \nThis will take the search query, create an embedding, find similar documents, and return them as a list of [Documents](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html).\n\n```python\nquery = "my query"\ndocs = vectorstore.similarity_search(query)\n```\n\n```python\nfrom langchain_community.vectorstores import FAISS\n\ndb = FAISS.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n  <TabItem value="lance" label="Lance">\n\nThis notebook shows how to use functionality related to the LanceDB vector database based on the Lance data format.\n\n```bash\npip install lancedb\n```\n\n```python\nfrom langchain_community.vectorstores import LanceDB\n\nimport lancedb\n\ndb = lancedb.connect("/tmp/lancedb")\ntable = db.create_table(\n    "my_table",\n    data=[\n        {\n            "vector": embeddings.embed_query("Hello World"),\n            "text": "Hello World",\n            "id": "1",\n        }\n    ],\n    mode="overwrite",\n)\ndb = LanceDB.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n</Tabs>\n\n\n## Similarity search\n\nAll vectorstores expose a `similarity_search` method.\nThis will take incoming documents, create an embedding of them, and then find all documents with the most similar embedding. \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@2fab0f8cc95b1ac7bc097d3efe5eb8d66de70af60f25e10c8b936932f2474160¢tsËAÚş14¨focus_msÍy§payload‚¤role©assistant§contentÚ{FAISS and Chroma are both vector stores that can be used in LangChain, with FAISS leveraging the Facebook AI Similarity Search library and Chroma functioning as a local library. FAISS is typically used for more complex similarity searches, while Chroma is simpler to set up and run locally. Both support a `similarity_search` method to find similar documents based on embeddings.ªfocus_kind¬exec_latency¨query_id¤Q004‰¢idÙ@e4040fb1f342b48a0c585f790f57903078c6d0de3b439e370084a4efbad3713a¢tsËAÚş1A}¨trace_idÙ$c8e4d0c8-2b15-4a22-8872-34940e020dc8­parent_run_idÙ$55094f6a-3064-4349-8fa4-f414d80003ff¦run_idÙ$c8e4d0c8-2b15-4a22-8872-34940e020dc8ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ{FAISS and Chroma are both vector stores that can be used in LangChain, with FAISS leveraging the Facebook AI Similarity Search library and Chroma functioning as a local library. FAISS is typically used for more complex similarity searches, while Chroma is simpler to set up and run locally. Both support a `similarity_search` method to find similar documents based on embeddings.¨query_id¤Q004ªfocus_kind¶chain_execution_result‹¢idÙ@ed492991944ba6dff96742fa5a3b0266f5249c93b8668530e7bcd9d8db936659¢tsËAÚş1L¨trace_id¤Q005­parent_run_idÀ¦run_idÙ$2322f089-406a-430e-886e-c03d3f55be8eªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?¨query_id¤Q005§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q005ªfocus_kind¯chain_execution‹¢idÙ@4d2703aadaf8421dc8a9e3f40687ecc3dd17b9c865696ec4e94c27606ffaf8e2¢tsËAÚş1V~¨trace_id¤Q005­parent_run_idÙ$2322f089-406a-430e-886e-c03d3f55be8e¦run_idÙ$35a442c4-174e-4fed-811b-7b0eb4ba455cªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?§context¦answer ¨query_id¤Q005¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q005®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:a72da615-591d-399b-acd0-33308646c91dªfocus_kind¯chain_execution‰¢idÙ@7b64ffd593bd700c48ab6f6f985e52fb7cb53d0480fa91e6920d0d10a87bd194¢tsËAÚş1²¨trace_idÙ$4facaeb6-7a37-45c1-917f-c48f317946bb­parent_run_idÙ$2322f089-406a-430e-886e-c03d3f55be8e¦run_idÙ$4facaeb6-7a37-45c1-917f-c48f317946bbªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# How to load Microsoft Office files

The [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, ...¨metadata¦sourceÙX/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/document_loader_office_file.mdx‚´page_content_summaryÙË## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader

[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known as `Azure Form Recognizer`) is machine-learning 
b...¨metadata¦sourceÙX/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/document_loader_office_file.mdx‚´page_content_summaryÙË### Prerequisite

An Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-s...¨metadata¦sourceÙX/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/document_loader_office_file.mdx¨query_id¤Q005¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?ªfocus_kind¶chain_execution_result‹¢idÙ@2dac126cc000e1be9349513eea801479091de3ac2bd0dcf024f898815c983140¢tsËAÚş1v¨trace_id¤Q005­parent_run_idÙ$2ca4c0db-817b-4824-b2dd-9fdf3dd1da92¦run_idÙ$0845cb2e-6a9d-40aa-ae28-f9e07620b07cªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?§contextÚ	°# How to load Microsoft Office files

The [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.

This covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a LangChain 
[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document)
object that we can use downstream.


## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader

## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader

[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known as `Azure Form Recognizer`) is machine-learning 
based service that extracts texts (including handwriting), tables, document structures (e.g., titles, section headings, etc.) and key-value-pairs from
digital or scanned PDFs, images, Office and HTML files. Document Intelligence supports `PDF`, `JPEG/JPG`, `PNG`, `BMP`, `TIFF`, `HEIF`, `DOCX`, `XLSX`, `PPTX` and `HTML`.

This [current implementation](https://aka.ms/di-langchain) of a loader using `Document Intelligence` can incorporate content page-wise and turn it into LangChain documents. The default output format is markdown, which can be easily chained with `MarkdownHeaderTextSplitter` for semantic document chunking. You can also use `mode="single"` or `mode="page"` to return pure texts in a single page or document split by page.

### Prerequisite

### Prerequisite

An Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don't have. You will be passing `<endpoint>` and `<key>` as parameters to the loader.

```python
%pip install --upgrade --quiet  langchain langchain-community azure-ai-documentintelligence

from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader

file_path = "<filepath>"
endpoint = "<endpoint>"
key = "<key>"
loader = AzureAIDocumentIntelligenceLoader(
    api_endpoint=endpoint, api_key=key, file_path=file_path, api_model="prebuilt-layout"
)

documents = loader.load()
```¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q005®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:91e47c1f-e40d-ead1-ead4-0d058bfbc2a6­checkpoint_nsÙ-generate:91e47c1f-e40d-ead1-ead4-0d058bfbc2a6¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@14a7222f26ad0b53a45d126c8adf9e9dc41f3e52a8677c24235610de15383c9d¢tsËAÚş1&™¨trace_idÙ$0845cb2e-6a9d-40aa-ae28-f9e07620b07c­parent_run_idÙ$2ca4c0db-817b-4824-b2dd-9fdf3dd1da92¦run_idÙ$0845cb2e-6a9d-40aa-ae28-f9e07620b07cªevent_type¬chain_output¬event_source¥chain§payload§outputsÚzmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: How can I load a Microsoft Word document into a LangChain pipeline? \nContext: # How to load Microsoft Office files\n\nThe [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n\nThis covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a LangChain \n[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document)\nobject that we can use downstream.\n\n\n## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader\n\n## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader\n\n[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known as `Azure Form Recognizer`) is machine-learning \nbased service that extracts texts (including handwriting), tables, document structures (e.g., titles, section headings, etc.) and key-value-pairs from\ndigital or scanned PDFs, images, Office and HTML files. Document Intelligence supports `PDF`, `JPEG/JPG`, `PNG`, `BMP`, `TIFF`, `HEIF`, `DOCX`, `XLSX`, `PPTX` and `HTML`.\n\nThis [current implementation](https://aka.ms/di-langchain) of a loader using `Document Intelligence` can incorporate content page-wise and turn it into LangChain documents. The default output format is markdown, which can be easily chained with `MarkdownHeaderTextSplitter` for semantic document chunking. You can also use `mode="single"` or `mode="page"` to return pure texts in a single page or document split by page.\n\n### Prerequisite\n\n### Prerequisite\n\nAn Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don\'t have. You will be passing `<endpoint>` and `<key>` as parameters to the loader.\n\n```python\n%pip install --upgrade --quiet  langchain langchain-community azure-ai-documentintelligence\n\nfrom langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n\nfile_path = "<filepath>"\nendpoint = "<endpoint>"\nkey = "<key>"\nloader = AzureAIDocumentIntelligenceLoader(\n    api_endpoint=endpoint, api_key=key, file_path=file_path, api_model="prebuilt-layout"\n)\n\ndocuments = loader.load()\n``` \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@c49acbe76df2cce4819db06904052c31835108efbd82a984a7ef22e145b795fd¢tsËAÚş1Œ\³¨focus_msÍè§payload‚¤role©assistant§contentÚYTo load a Microsoft Word document into a LangChain pipeline, you can use the `AzureAIDocumentIntelligenceLoader`. First, ensure you have an Azure AI Document Intelligence resource set up, then use the loader with your file path, endpoint, and key to load the document. The code snippet provided in the context demonstrates how to implement this.ªfocus_kind¬exec_latency¨query_id¤Q005‰¢idÙ@cc7fe142f88b2b7f0e26939a33f4ebb0600bd226f8580fd4aab3a3aba6caeb96¢tsËAÚş1Œhí¨trace_idÙ$2ca4c0db-817b-4824-b2dd-9fdf3dd1da92­parent_run_idÙ$2322f089-406a-430e-886e-c03d3f55be8e¦run_idÙ$2ca4c0db-817b-4824-b2dd-9fdf3dd1da92ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚYTo load a Microsoft Word document into a LangChain pipeline, you can use the `AzureAIDocumentIntelligenceLoader`. First, ensure you have an Azure AI Document Intelligence resource set up, then use the loader with your file path, endpoint, and key to load the document. The code snippet provided in the context demonstrates how to implement this.¨query_id¤Q005ªfocus_kind¶chain_execution_result‹¢idÙ@1e8734d8bb0fd2f8bb1c0665225b5042808ce2220f0ac60f3d83127bcf4cea73¢tsËAÚş1Œrë¨trace_id¤Q006­parent_run_idÀ¦run_idÙ$b1066281-fe23-4951-b9ab-a1aa497b0d7bªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ2Describe the Runnable protocol and its advantages.¨query_id¤Q006§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q006ªfocus_kind¯chain_execution‹¢idÙ@ebf3aba71016d13f6e4a4934f6abf0d8f06b5887066bc9672e765ee62ff00b8a¢tsËAÚş1Œ|»¨trace_id¤Q006­parent_run_idÙ$b1066281-fe23-4951-b9ab-a1aa497b0d7b¦run_idÙ$2be917dd-19e7-4a2e-9c18-72a1d58f046aªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ2Describe the Runnable protocol and its advantages.§context¦answer ¨query_id¤Q006¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q006®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:ac9e3c2d-d3d8-f77b-863a-0b61f2c59183ªfocus_kind¯chain_execution‰¢idÙ@888f85ffa727faeedec64c2d54e8e114cd860e903201e6cf23f998ca3bf00a8e¢tsËAÚş1¤¨¨trace_idÙ$9ab45107-5ee8-446b-a089-6db0879a800d­parent_run_idÙ$b1066281-fe23-4951-b9ab-a1aa497b0d7b¦run_idÙ$9ab45107-5ee8-446b-a089-6db0879a800dªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Runnable interface

The Runnable interface is the foundation for working with LangChain components, and it's implemented across many of them, such as [language models](/docs/concepts/chat_models), [...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/runnables.mdx‚´page_content_summaryÙË## Overview of runnable interface

The Runnable way defines a standard interface that allows a Runnable component to be:

* [Invoked](/docs/how_to/lcel_cheatsheet/#invoke-a-runnable): A single input i...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/runnables.mdx‚´page_content_summaryÙËThis guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.

:::info Relate...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/runnables.mdx¨query_id¤Q006¨questionÙ2Describe the Runnable protocol and its advantages.ªfocus_kind¶chain_execution_result‹¢idÙ@2875439aa2ac54122525508f61660815015ea5126ddb1f102edeea4ea796e46c¢tsËAÚş1¤& ¨trace_id¤Q006­parent_run_idÙ$85ae66b1-9b84-4639-b140-479631335bd2¦run_idÙ$0c7a72ec-28c2-43a9-9f49-7c8e95038795ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ2Describe the Runnable protocol and its advantages.§contextÚ	£# Runnable interface

The Runnable interface is the foundation for working with LangChain components, and it's implemented across many of them, such as [language models](/docs/concepts/chat_models), [output parsers](/docs/concepts/output_parsers), [retrievers](/docs/concepts/retrievers), [compiled LangGraph graphs](
https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) and more.

This guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.

## Overview of runnable interface

The Runnable way defines a standard interface that allows a Runnable component to be:

* [Invoked](/docs/how_to/lcel_cheatsheet/#invoke-a-runnable): A single input is transformed into an output.
* [Batched](/docs/how_to/lcel_cheatsheet/#batch-a-runnable): Multiple inputs are efficiently transformed into outputs.
* [Streamed](/docs/how_to/lcel_cheatsheet/#stream-a-runnable): Outputs are streamed as they are produced.
* Inspected: Schematic information about Runnable's input, output, and configuration can be accessed.
* Composed: Multiple Runnables can be composed to work together using [the LangChain Expression Language (LCEL)](/docs/concepts/lcel) to create complex pipelines.

Please review the [LCEL Cheatsheet](/docs/how_to/lcel_cheatsheet) for some common patterns that involve the Runnable interface and LCEL expressions.

<a id="batch"></a>
### Optimized parallel execution (batch)
<span data-heading-keywords="batch"></span>

This guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.

:::info Related Resources
* The ["Runnable" Interface API Reference](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) provides a detailed overview of the Runnable interface and its methods.
* A list of built-in `Runnables` can be found in the [LangChain Core API Reference](https://python.langchain.com/api_reference/core/runnables.html). Many of these Runnables are useful when composing custom "chains" in LangChain using the [LangChain Expression Language (LCEL)](/docs/concepts/lcel).
:::

## Overview of runnable interface

The Runnable way defines a standard interface that allows a Runnable component to be:¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q006®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:94c64494-d50d-2aeb-1dfb-a09c74f47f56­checkpoint_nsÙ-generate:94c64494-d50d-2aeb-1dfb-a09c74f47f56¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@1469e720a3570780314eed1aefcf3d5873e8044c89e75b3b04c2fc10e4cecddc¢tsËAÚş1¤.w¨trace_idÙ$0c7a72ec-28c2-43a9-9f49-7c8e95038795­parent_run_idÙ$85ae66b1-9b84-4639-b140-479631335bd2¦run_idÙ$0c7a72ec-28c2-43a9-9f49-7c8e95038795ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚWmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Describe the Runnable protocol and its advantages. \nContext: # Runnable interface\n\nThe Runnable interface is the foundation for working with LangChain components, and it\'s implemented across many of them, such as [language models](/docs/concepts/chat_models), [output parsers](/docs/concepts/output_parsers), [retrievers](/docs/concepts/retrievers), [compiled LangGraph graphs](\nhttps://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) and more.\n\nThis guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.\n\n## Overview of runnable interface\n\nThe Runnable way defines a standard interface that allows a Runnable component to be:\n\n* [Invoked](/docs/how_to/lcel_cheatsheet/#invoke-a-runnable): A single input is transformed into an output.\n* [Batched](/docs/how_to/lcel_cheatsheet/#batch-a-runnable): Multiple inputs are efficiently transformed into outputs.\n* [Streamed](/docs/how_to/lcel_cheatsheet/#stream-a-runnable): Outputs are streamed as they are produced.\n* Inspected: Schematic information about Runnable\'s input, output, and configuration can be accessed.\n* Composed: Multiple Runnables can be composed to work together using [the LangChain Expression Language (LCEL)](/docs/concepts/lcel) to create complex pipelines.\n\nPlease review the [LCEL Cheatsheet](/docs/how_to/lcel_cheatsheet) for some common patterns that involve the Runnable interface and LCEL expressions.\n\n<a id="batch"></a>\n### Optimized parallel execution (batch)\n<span data-heading-keywords="batch"></span>\n\nThis guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.\n\n:::info Related Resources\n* The ["Runnable" Interface API Reference](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) provides a detailed overview of the Runnable interface and its methods.\n* A list of built-in `Runnables` can be found in the [LangChain Core API Reference](https://python.langchain.com/api_reference/core/runnables.html). Many of these Runnables are useful when composing custom "chains" in LangChain using the [LangChain Expression Language (LCEL)](/docs/concepts/lcel).\n:::\n\n## Overview of runnable interface\n\nThe Runnable way defines a standard interface that allows a Runnable component to be: \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@b3605b97c137bbfe44568fb1cc3de4b2258646cd5ba9bd74802d11b3d1730dff¢tsËAÚş1ù(å¨focus_msÍ/§payload‚¤role©assistant§contentÚ–The Runnable protocol is a standard interface in LangChain that allows components to be invoked, batched, streamed, inspected, and composed. Its advantages include consistent interaction with various components, efficient processing of multiple inputs, and the ability to create complex pipelines through composition. This enhances flexibility and predictability in developing applications using LangChain.ªfocus_kind¬exec_latency¨query_id¤Q006‰¢idÙ@dd84603a9deb82e030ed7cc54e4865f19aae54e45f2e81337d9bd6944587f3cb¢tsËAÚş1ù4Ó¨trace_idÙ$85ae66b1-9b84-4639-b140-479631335bd2­parent_run_idÙ$b1066281-fe23-4951-b9ab-a1aa497b0d7b¦run_idÙ$85ae66b1-9b84-4639-b140-479631335bd2ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ–The Runnable protocol is a standard interface in LangChain that allows components to be invoked, batched, streamed, inspected, and composed. Its advantages include consistent interaction with various components, efficient processing of multiple inputs, and the ability to create complex pipelines through composition. This enhances flexibility and predictability in developing applications using LangChain.¨query_id¤Q006ªfocus_kind¶chain_execution_result‹¢idÙ@e06f7e427050e151cc11accfe89a8b9d02b250c94cd4e9c93d0d05cd535d7e82¢tsËAÚş1ù=i¨trace_id¤Q007­parent_run_idÀ¦run_idÙ$056a0e7a-e558-4ace-bb41-746457a11c27ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3What is Few-Shot prompting and how is it supported?¨query_id¤Q007§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q007ªfocus_kind¯chain_execution‹¢idÙ@b43696354733b74c5eaa08e5c15e319c2a3de08758efcca39d629cb19260cfa1¢tsËAÚş1ùEF¨trace_id¤Q007­parent_run_idÙ$056a0e7a-e558-4ace-bb41-746457a11c27¦run_idÙ$3a208926-5c51-46c9-814a-cb45dc42cbbfªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3What is Few-Shot prompting and how is it supported?§context¦answer ¨query_id¤Q007¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q007®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:022ca48d-6abb-a297-4827-4dacd207635dªfocus_kind¯chain_execution‰¢idÙ@fa2281bada03496f2b5ef8c1cc0d015bf782e34aab33f93dd7bf533cbf112bce¢tsËAÚş2!d¨trace_idÙ$61c6e1d0-4e40-4c0e-965d-58d530671fcd­parent_run_idÙ$056a0e7a-e558-4ace-bb41-746457a11c27¦run_idÙ$61c6e1d0-4e40-4c0e-965d-58d530671fcdªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Few-shot prompting

:::note Prerequisites

- [Chat models](/docs/concepts/chat_models/)
:::

## Overview

One of the most effective ways to improve model performance is to give a model examples of
w...¨metadata¦sourceÙQ/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/few_shot_prompting.mdx‚´page_content_summaryÙËThese requirements are model-specific and should be checked for the model you are using. If your model requires ToolMessages after tool calls and/or AIMessages after ToolMessages and your examples onl...¨metadata¦sourceÙQ/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/few_shot_prompting.mdx‚´page_content_summaryÙË### Example selectors

[Example Selectors](/docs/concepts/example_selectors) are responsible for selecting the correct few shot examples to pass to the prompt.

- [How to: use example selectors](/docs...¨metadata¦sourceÙB/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/index.mdx¨query_id¤Q007¨questionÙ3What is Few-Shot prompting and how is it supported?ªfocus_kind¶chain_execution_result‹¢idÙ@0c710e8a35a5e7c23cbe71045773b3956bc144b6f6f7930f6e4a29318fde8b13¢tsËAÚş2-¨trace_id¤Q007­parent_run_idÙ$29a9b538-9ad6-4818-a1a0-dc80325d9896¦run_idÙ$e9ade68e-8ec2-4c14-be59-19fc55647d9aªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ3What is Few-Shot prompting and how is it supported?§contextÚ
6# Few-shot prompting

:::note Prerequisites

- [Chat models](/docs/concepts/chat_models/)
:::

## Overview

One of the most effective ways to improve model performance is to give a model examples of
what you want it to do. The technique of adding example inputs and expected outputs
to a model prompt is known as "few-shot prompting". The technique is based on the
[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) paper.
There are a few things to think about when doing few-shot prompting:

1. How are examples generated?
2. How many examples are in each prompt?
3. How are examples selected at runtime?
4. How are examples formatted in the prompt?

Here are the considerations for each.

## 1. Generating examples

The first and most important step of few-shot prompting is coming up with a good dataset of examples. Good examples should be relevant at runtime, clear, informative, and provide information that was not already known to the model.

These requirements are model-specific and should be checked for the model you are using. If your model requires ToolMessages after tool calls and/or AIMessages after ToolMessages and your examples only include expected tool calls and not the actual tool outputs, you can try adding dummy ToolMessages / AIMessages to the end of each example with generic contents to satisfy the API constraints.
In these cases it's especially worth experimenting with inserting your examples as strings versus messages, as having dummy messages can adversely affect certain models.

You can see a case study of how Anthropic and OpenAI respond to different few-shot prompting techniques on two different tool calling benchmarks [here](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/).

### Example selectors

[Example Selectors](/docs/concepts/example_selectors) are responsible for selecting the correct few shot examples to pass to the prompt.

- [How to: use example selectors](/docs/how_to/example_selectors)
- [How to: select examples by length](/docs/how_to/example_selectors_length_based)
- [How to: select examples by semantic similarity](/docs/how_to/example_selectors_similarity)
- [How to: select examples by semantic ngram overlap](/docs/how_to/example_selectors_ngram)
- [How to: select examples by maximal marginal relevance](/docs/how_to/example_selectors_mmr)
- [How to: select examples from LangSmith few-shot datasets](/docs/how_to/example_selectors_langsmith/)

### LLMs

What LangChain calls [LLMs](/docs/concepts/text_llms) are older forms of language models that take a string in and output a string.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q007®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:41d4a842-cc11-5271-9bae-652ff0983657­checkpoint_nsÙ-generate:41d4a842-cc11-5271-9bae-652ff0983657¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@d59581283d0fc70572fa97245414423d42a17cfc6418f230b89df3d61caa08de¢tsËAÚş26X¨trace_idÙ$e9ade68e-8ec2-4c14-be59-19fc55647d9a­parent_run_idÙ$29a9b538-9ad6-4818-a1a0-dc80325d9896¦run_idÙ$e9ade68e-8ec2-4c14-be59-19fc55647d9aªevent_type¬chain_output¬event_source¥chain§payload§outputsÚömessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: What is Few-Shot prompting and how is it supported? \nContext: # Few-shot prompting\n\n:::note Prerequisites\n\n- [Chat models](/docs/concepts/chat_models/)\n:::\n\n## Overview\n\nOne of the most effective ways to improve model performance is to give a model examples of\nwhat you want it to do. The technique of adding example inputs and expected outputs\nto a model prompt is known as "few-shot prompting". The technique is based on the\n[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) paper.\nThere are a few things to think about when doing few-shot prompting:\n\n1. How are examples generated?\n2. How many examples are in each prompt?\n3. How are examples selected at runtime?\n4. How are examples formatted in the prompt?\n\nHere are the considerations for each.\n\n## 1. Generating examples\n\nThe first and most important step of few-shot prompting is coming up with a good dataset of examples. Good examples should be relevant at runtime, clear, informative, and provide information that was not already known to the model.\n\nThese requirements are model-specific and should be checked for the model you are using. If your model requires ToolMessages after tool calls and/or AIMessages after ToolMessages and your examples only include expected tool calls and not the actual tool outputs, you can try adding dummy ToolMessages / AIMessages to the end of each example with generic contents to satisfy the API constraints.\nIn these cases it\'s especially worth experimenting with inserting your examples as strings versus messages, as having dummy messages can adversely affect certain models.\n\nYou can see a case study of how Anthropic and OpenAI respond to different few-shot prompting techniques on two different tool calling benchmarks [here](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/).\n\n### Example selectors\n\n[Example Selectors](/docs/concepts/example_selectors) are responsible for selecting the correct few shot examples to pass to the prompt.\n\n- [How to: use example selectors](/docs/how_to/example_selectors)\n- [How to: select examples by length](/docs/how_to/example_selectors_length_based)\n- [How to: select examples by semantic similarity](/docs/how_to/example_selectors_similarity)\n- [How to: select examples by semantic ngram overlap](/docs/how_to/example_selectors_ngram)\n- [How to: select examples by maximal marginal relevance](/docs/how_to/example_selectors_mmr)\n- [How to: select examples from LangSmith few-shot datasets](/docs/how_to/example_selectors_langsmith/)\n\n### LLMs\n\nWhat LangChain calls [LLMs](/docs/concepts/text_llms) are older forms of language models that take a string in and output a string. \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@cd8e0b7651046df0d7a17a80800c56a68e068807664da68e671cae521fc51c83¢tsËAÚş2`ÀÆ¨focus_msÍ§payload‚¤role©assistant§contentÚFew-shot prompting is a technique that enhances model performance by providing examples of desired inputs and outputs within a prompt. It is supported by carefully generating relevant examples, selecting the appropriate ones at runtime, and formatting them correctly in the prompt. This approach is based on the principles outlined in the "Language Models are Few-Shot Learners" paper.ªfocus_kind¬exec_latency¨query_id¤Q007‰¢idÙ@792cddec49c77ae48239c34caebd01601560967048ae7833f33bfc78801f3b84¢tsËAÚş2`Í…¨trace_idÙ$29a9b538-9ad6-4818-a1a0-dc80325d9896­parent_run_idÙ$056a0e7a-e558-4ace-bb41-746457a11c27¦run_idÙ$29a9b538-9ad6-4818-a1a0-dc80325d9896ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚFew-shot prompting is a technique that enhances model performance by providing examples of desired inputs and outputs within a prompt. It is supported by carefully generating relevant examples, selecting the appropriate ones at runtime, and formatting them correctly in the prompt. This approach is based on the principles outlined in the "Language Models are Few-Shot Learners" paper.¨query_id¤Q007ªfocus_kind¶chain_execution_result‹¢idÙ@6fb46a85b5d09b06666868dd3fab6026ec4a97bb70a728e86d347d2505a2d431¢tsËAÚş2`Ö™¨trace_id¤Q008­parent_run_idÀ¦run_idÙ$15cb4b60-5b54-404d-93a0-43281d8b1992ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ<Give an example of a memory object that stores chat history.¨query_id¤Q008§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q008ªfocus_kind¯chain_execution‹¢idÙ@f45bd2342d326d100fee09ebf42becb8de703fe6a72d10dca78c68a5e4967c56¢tsËAÚş2`Ş7¨trace_id¤Q008­parent_run_idÙ$15cb4b60-5b54-404d-93a0-43281d8b1992¦run_idÙ$72c4a2b6-1e5f-4aeb-81a8-65a5e1ceb943ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ<Give an example of a memory object that stores chat history.§context¦answer ¨query_id¤Q008¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q008®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:32c9b399-aa13-e18b-4285-73f259077461ªfocus_kind¯chain_execution‰¢idÙ@a61214024cfe3a803ade8836124e4aec18ee8cab13c5d40a094d25a0bb7f9cf5¢tsËAÚş2t¨›¨trace_idÙ$59a3827f-6f85-41a9-a21a-fdc23f242aad­parent_run_idÙ$15cb4b60-5b54-404d-93a0-43281d8b1992¦run_idÙ$59a3827f-6f85-41a9-a21a-fdc23f242aadªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙËWhile processing chat history, it's essential to preserve a correct conversation structure. 

Key guidelines for managing chat history:

- The conversation should follow one of these structures:
    -...¨metadata¦sourceÙK/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/chat_history.mdx‚´page_content_summaryÙËThe **assistant** may respond directly to the user or if configured with tools request that a [tool](/docs/concepts/tool_calling) be invoked to perform a specific task.

A full conversation often invo...¨metadata¦sourceÙK/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/chat_history.mdx‚´page_content_summaryÙË## Related resources

- [How to trim messages](/docs/how_to/trim_messages/)
- [Memory guide](https://langchain-ai.github.io/langgraph/concepts/memory/) for information on implementing short-term and l...¨metadata¦sourceÙK/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/chat_history.mdx¨query_id¤Q008¨questionÙ<Give an example of a memory object that stores chat history.ªfocus_kind¶chain_execution_result‹¢idÙ@3fb0c589a8f119ee3dbb776235a9386b2a8b3d8d320af001a974d71ef5613646¢tsËAÚş2t´_¨trace_id¤Q008­parent_run_idÙ$22bd8f02-ba93-4637-b1e7-cc4662d45ff0¦run_idÙ$7fe3d896-4132-428e-99f5-03f4dbaa6e2fªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ<Give an example of a memory object that stores chat history.§contextÚ´While processing chat history, it's essential to preserve a correct conversation structure. 

Key guidelines for managing chat history:

- The conversation should follow one of these structures:
    - The first message is either a "user" message or a "system" message, followed by a "user" and then an "assistant" message.
    - The last message should be either a "user" message or a "tool" message containing the result of a tool call.
- When using [tool calling](/docs/concepts/tool_calling), a "tool" message should only follow an "assistant" message that requested the tool invocation.

:::tip
Understanding correct conversation structure is essential for being able to properly implement
[memory](https://langchain-ai.github.io/langgraph/concepts/memory/) in chat models.
:::

## Related resources

The **assistant** may respond directly to the user or if configured with tools request that a [tool](/docs/concepts/tool_calling) be invoked to perform a specific task.

A full conversation often involves a combination of two patterns of alternating messages:

1. The **user** and the **assistant** representing a back-and-forth conversation.
2. The **assistant** and **tool messages** representing an ["agentic" workflow](/docs/concepts/agents) where the assistant is invoking tools to perform specific tasks.

## Managing chat history

Since chat models have a maximum limit on input size, it's important to manage chat history and trim it as needed to avoid exceeding the [context window](/docs/concepts/chat_models/#context-window).

While processing chat history, it's essential to preserve a correct conversation structure. 

Key guidelines for managing chat history:

## Related resources

- [How to trim messages](/docs/how_to/trim_messages/)
- [Memory guide](https://langchain-ai.github.io/langgraph/concepts/memory/) for information on implementing short-term and long-term memory in chat models using [LangGraph](https://langchain-ai.github.io/langgraph/).¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q008®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:9515d1ab-2479-8650-9aeb-96ac88ec94e0­checkpoint_nsÙ-generate:9515d1ab-2479-8650-9aeb-96ac88ec94e0¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@018a269a3a7a4d1d10cc6e054376ea31a1b0b8c50f6b1a1327491be8802e6fd9¢tsËAÚş2t»t¨trace_idÙ$7fe3d896-4132-428e-99f5-03f4dbaa6e2f­parent_run_idÙ$22bd8f02-ba93-4637-b1e7-cc4662d45ff0¦run_idÙ$7fe3d896-4132-428e-99f5-03f4dbaa6e2fªevent_type¬chain_output¬event_source¥chain§payload§outputsÚ	umessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Give an example of a memory object that stores chat history. \nContext: While processing chat history, it\'s essential to preserve a correct conversation structure. \n\nKey guidelines for managing chat history:\n\n- The conversation should follow one of these structures:\n    - The first message is either a "user" message or a "system" message, followed by a "user" and then an "assistant" message.\n    - The last message should be either a "user" message or a "tool" message containing the result of a tool call.\n- When using [tool calling](/docs/concepts/tool_calling), a "tool" message should only follow an "assistant" message that requested the tool invocation.\n\n:::tip\nUnderstanding correct conversation structure is essential for being able to properly implement\n[memory](https://langchain-ai.github.io/langgraph/concepts/memory/) in chat models.\n:::\n\n## Related resources\n\nThe **assistant** may respond directly to the user or if configured with tools request that a [tool](/docs/concepts/tool_calling) be invoked to perform a specific task.\n\nA full conversation often involves a combination of two patterns of alternating messages:\n\n1. The **user** and the **assistant** representing a back-and-forth conversation.\n2. The **assistant** and **tool messages** representing an ["agentic" workflow](/docs/concepts/agents) where the assistant is invoking tools to perform specific tasks.\n\n## Managing chat history\n\nSince chat models have a maximum limit on input size, it\'s important to manage chat history and trim it as needed to avoid exceeding the [context window](/docs/concepts/chat_models/#context-window).\n\nWhile processing chat history, it\'s essential to preserve a correct conversation structure. \n\nKey guidelines for managing chat history:\n\n## Related resources\n\n- [How to trim messages](/docs/how_to/trim_messages/)\n- [Memory guide](https://langchain-ai.github.io/langgraph/concepts/memory/) for information on implementing short-term and long-term memory in chat models using [LangGraph](https://langchain-ai.github.io/langgraph/). \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@2bec21732f2f4a611d1bb30e38346df7946cb811311472015df7494d547a1821¢tsËAÚş2·t£¨focus_msÍ§payload‚¤role©assistant§contentÚ7An example of a memory object that stores chat history could be a structured list or array that maintains the sequence of messages, including user, assistant, and tool messages. This object would ensure that the conversation follows the correct structure and adheres to the guidelines for managing chat history.ªfocus_kind¬exec_latency¨query_id¤Q008‰¢idÙ@9386872a797802849552db09f4c1aca78191e261d91501078773487840a73a4b¢tsËAÚş2·„Û¨trace_idÙ$22bd8f02-ba93-4637-b1e7-cc4662d45ff0­parent_run_idÙ$15cb4b60-5b54-404d-93a0-43281d8b1992¦run_idÙ$22bd8f02-ba93-4637-b1e7-cc4662d45ff0ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ7An example of a memory object that stores chat history could be a structured list or array that maintains the sequence of messages, including user, assistant, and tool messages. This object would ensure that the conversation follows the correct structure and adheres to the guidelines for managing chat history.¨query_id¤Q008ªfocus_kind¶chain_execution_result‹¢idÙ@6e51509d2d1940919746fe6262b3fb9a4b072983ab286d3dae946376fcaf27e4¢tsËAÚş2·C¨trace_id¤Q009­parent_run_idÀ¦run_idÙ$b8f42485-7bac-4277-97c1-06a341a23ba6ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ9Outline the steps to trace a LangGraph flow in LangSmith.¨query_id¤Q009§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q009ªfocus_kind¯chain_execution‹¢idÙ@c9290b99fc2ac69f40e9b986723e466c7109fa4f4c005523b3e5b689ada7120f¢tsËAÚş2·™¨trace_id¤Q009­parent_run_idÙ$b8f42485-7bac-4277-97c1-06a341a23ba6¦run_idÙ$95d64177-b081-4b3d-94fb-8940738f4d3bªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ9Outline the steps to trace a LangGraph flow in LangSmith.§context¦answer ¨query_id¤Q009¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q009®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:229a4b7f-e99a-e3e7-5226-1831695065f5ªfocus_kind¯chain_execution‰¢idÙ@79398a1b9c28db50f51a1c15f8b812a25720068a4737e15904d5dadb0ab3ab3e¢tsËAÚş2Ä¿¨trace_idÙ$6174151a-b20a-4a65-86f4-ef27eab37aed­parent_run_idÙ$b8f42485-7bac-4277-97c1-06a341a23ba6¦run_idÙ$6174151a-b20a-4a65-86f4-ef27eab37aedªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË## LangSmith

LangSmith allows you to closely trace, monitor and evaluate your LLM application.
It seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of you...¨metadata¦sourceÙE/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/tutorials/index.mdx‚´page_content_summaryÙË[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like incl...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx‚´page_content_summaryÙË## [LangGraph](https://langchain-ai.github.io/langgraph)

LangGraph is an extension of LangChain aimed at
building robust and stateful multi-actor applications with LLMs by modeling steps as edges and...¨metadata¦sourceÙB/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/index.mdx¨query_id¤Q009¨questionÙ9Outline the steps to trace a LangGraph flow in LangSmith.ªfocus_kind¶chain_execution_result‹¢idÙ@56a8ebc610260e0607a3e14d8ad41192372fee99ddc371cc7779e2af711c5dc6¢tsËAÚş2Äf¨trace_id¤Q009­parent_run_idÙ$4b7a209b-8a01-467c-a0c1-5bb88cde52c0¦run_idÙ$f79fd79f-2343-4ef5-8720-ae45c7073e6cªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ9Outline the steps to trace a LangGraph flow in LangSmith.§contextÚ¯## LangSmith

LangSmith allows you to closely trace, monitor and evaluate your LLM application.
It seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.

LangSmith documentation is hosted on a separate site.
You can peruse [LangSmith tutorials here](https://docs.smith.langchain.com/).

### Evaluation

LangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:

- [Evaluate your LLM application](https://docs.smith.langchain.com/tutorials/Developers/evaluation)

[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like including [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/), [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/), or [memory](https://langchain-ai.github.io/langgraph/concepts/memory/).

[LangSmith](https://docs.smith.langchain.com/) makes it possible to iterate with confidence on your applications, by providing LLM-specific observability and framework for testing and evaluating your application.

## [LangGraph](https://langchain-ai.github.io/langgraph)

LangGraph is an extension of LangChain aimed at
building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.

LangGraph documentation is currently hosted on a separate site.
You can peruse [LangGraph how-to guides here](https://langchain-ai.github.io/langgraph/how-tos/).

## [LangSmith](https://docs.smith.langchain.com/)

LangSmith allows you to closely trace, monitor and evaluate your LLM application.
It seamlessly integrates with LangChain and LangGraph, and you can use it to inspect and debug individual steps of your chains and agents as you build.

LangSmith documentation is hosted on a separate site.
You can peruse [LangSmith how-to guides here](https://docs.smith.langchain.com/), but we'll highlight a few sections that are particularly
relevant to LangChain below:

### Evaluation
<span data-heading-keywords="evaluation,evaluate"></span>¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q009®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:8f4ddba1-fd63-97f0-11ad-760c4338b898­checkpoint_nsÙ-generate:8f4ddba1-fd63-97f0-11ad-760c4338b898¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@a22c96a76cf139c2af8169d433254c179bbb2be1349bbe66a8be88b790e715f3¢tsËAÚş2Ä+R¨trace_idÙ$f79fd79f-2343-4ef5-8720-ae45c7073e6c­parent_run_idÙ$4b7a209b-8a01-467c-a0c1-5bb88cde52c0¦run_idÙ$f79fd79f-2343-4ef5-8720-ae45c7073e6cªevent_type¬chain_output¬event_source¥chain§payload§outputsÚ
mmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Outline the steps to trace a LangGraph flow in LangSmith. \nContext: ## LangSmith\n\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\n\nLangSmith documentation is hosted on a separate site.\nYou can peruse [LangSmith tutorials here](https://docs.smith.langchain.com/).\n\n### Evaluation\n\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\n\n- [Evaluate your LLM application](https://docs.smith.langchain.com/tutorials/Developers/evaluation)\n\n[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like including [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/), [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/), or [memory](https://langchain-ai.github.io/langgraph/concepts/memory/).\n\n[LangSmith](https://docs.smith.langchain.com/) makes it possible to iterate with confidence on your applications, by providing LLM-specific observability and framework for testing and evaluating your application.\n\n## [LangGraph](https://langchain-ai.github.io/langgraph)\n\nLangGraph is an extension of LangChain aimed at\nbuilding robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.\n\nLangGraph documentation is currently hosted on a separate site.\nYou can peruse [LangGraph how-to guides here](https://langchain-ai.github.io/langgraph/how-tos/).\n\n## [LangSmith](https://docs.smith.langchain.com/)\n\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\nIt seamlessly integrates with LangChain and LangGraph, and you can use it to inspect and debug individual steps of your chains and agents as you build.\n\nLangSmith documentation is hosted on a separate site.\nYou can peruse [LangSmith how-to guides here](https://docs.smith.langchain.com/), but we\'ll highlight a few sections that are particularly\nrelevant to LangChain below:\n\n### Evaluation\n<span data-heading-keywords="evaluation,evaluate"></span> \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result‰¢idÙ@fb677cb54139d05d3b57021caa0de985b83b78c7f081605689f2d58ced8c4b54¢tsËAÚş2ÛğN¨trace_idÙ$f93ea59f-385a-4d3c-8320-8f72854bbb5b­parent_run_idÙ$4b7a209b-8a01-467c-a0c1-5bb88cde52c0¦run_idÙ$f93ea59f-385a-4d3c-8320-8f72854bbb5bªevent_type©llm_error¬event_source£llm§payload¥error ªfocus_kind¥error‰¢idÙ@87d7165308772a9d5721732ba3ac0a0998b88f8664d8c4ef0502265f81bbcedf¢tsËAÚş2Ûø<¨trace_idÙ$4b7a209b-8a01-467c-a0c1-5bb88cde52c0­parent_run_idÙ$b8f42485-7bac-4277-97c1-06a341a23ba6¦run_idÙ$4b7a209b-8a01-467c-a0c1-5bb88cde52c0ªevent_type«chain_error¬event_source¥chain§payload¥error ªfocus_kind¥error‰¢idÙ@cc9b76b4d730dfbf40ada6decf78363d77c3c5dc3aebfa014f866f1dd73ce821¢tsËAÚş2Ûür¨trace_idÙ$b8f42485-7bac-4277-97c1-06a341a23ba6­parent_run_idÀ¦run_idÙ$b8f42485-7bac-4277-97c1-06a341a23ba6ªevent_type«chain_error¬event_source¥chain§payload¥error ªfocus_kind¥error