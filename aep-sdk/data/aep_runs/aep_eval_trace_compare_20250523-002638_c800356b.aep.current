‹¢idÙ@be55a313d434b0bae69d5f6fe6936abc2afb4eea2bbee4ccbf8316918785184c¢tsËAÚşp¢ç¨trace_id¤Q000­parent_run_idÀ¦run_idÙ$422f8817-09c0-4066-9b75-e004f1f783a2ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ)What is LangChain and why was it created?¨query_id¤Q000§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q000ªfocus_kind¯chain_execution‹¢idÙ@d03f0d61ae1aebc8a5603fb2d648e4a8e389bd1a4fbee02540f1642961860c1a¢tsËAÚşp¢+Ü¨trace_id¤Q000­parent_run_idÙ$422f8817-09c0-4066-9b75-e004f1f783a2¦run_idÙ$fe9b93c8-d6b7-4b4e-8975-6b9a48d8440dªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ)What is LangChain and why was it created?§context¦answer ¨query_id¤Q000¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q000®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:0c2dab14-df50-0e50-6594-bc08cea9b781ªfocus_kind¯chain_execution‰¢idÙ@caad534d47c832ac806f2648d666e9fe0c7e6d3bb6f7d8721a5c1d2af7a06091¢tsËAÚşp³!J¨trace_idÙ$b453294c-b2f3-442b-b4fb-d5073b9b1b09­parent_run_idÙ$422f8817-09c0-4066-9b75-e004f1f783a2¦run_idÙ$b453294c-b2f3-442b-b4fb-d5073b9b1b09ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Why LangChain?

The goal of `langchain` the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.
While LangChain originally st...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx‚´page_content_summaryÙË## Features

There are several primary needs that LangChain aims to address:

1. **Standardized component interfaces:** The growing number of [models](/docs/integrations/chat/) and [related components...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx‚´page_content_summaryÙË---
sidebar_position: 0
sidebar_class_name: hidden
---

# Introduction

**LangChain** is a framework for developing applications powered by large language models (LLMs).

LangChain simplifies every st...¨metadata¦sourceÙB/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/introduction.mdx¨query_id¤Q000¨questionÙ)What is LangChain and why was it created?ªfocus_kind¶chain_execution_result‹¢idÙ@65d53c4d6ca2ab4b7115f4e5b716b38d6834687c2dec472737fd8626d9990784¢tsËAÚşp³eM¨trace_id¤Q000­parent_run_idÙ$6eddde57-d401-408e-b794-85dc6f672b5f¦run_idÙ$7c7176de-05c8-4d94-aa41-7f296cf35a17ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ)What is LangChain and why was it created?§contextÚ×# Why LangChain?

The goal of `langchain` the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.
While LangChain originally started as a single open source package, it has evolved into a company and a whole ecosystem.
This page will talk about the LangChain ecosystem as a whole.
Most of the components within the LangChain ecosystem can be used by themselves - so if you feel particularly drawn to certain components but not others, that is totally fine! Pick and choose whichever components you like best for your own use case!

## Features

There are several primary needs that LangChain aims to address:

## Features

There are several primary needs that LangChain aims to address:

1. **Standardized component interfaces:** The growing number of [models](/docs/integrations/chat/) and [related components](/docs/integrations/vectorstores/) for AI applications has resulted in a wide variety of different APIs that developers need to learn and use.
This diversity can make it challenging for developers to switch between providers or combine components when building applications.
LangChain exposes a standard interface for key components, making it easy to switch between providers.

---
sidebar_position: 0
sidebar_class_name: hidden
---

# Introduction

**LangChain** is a framework for developing applications powered by large language models (LLMs).

LangChain simplifies every stage of the LLM application lifecycle:
- **Development**: Build your applications using LangChain's open-source [components](/docs/concepts) and [third-party integrations](/docs/integrations/providers/).
Use [LangGraph](/docs/concepts/architecture/#langgraph) to build stateful agents with first-class streaming and human-in-the-loop support.
- **Productionization**: Use [LangSmith](https://docs.smith.langchain.com/) to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.
- **Deployment**: Turn your LangGraph applications into production-ready APIs and Assistants with [LangGraph Platform](https://langchain-ai.github.io/langgraph/cloud/).

import ThemedImage from '@theme/ThemedImage';
import useBaseUrl from '@docusaurus/useBaseUrl';¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q000®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:17a086c3-c037-25be-9512-a65b2286901f­checkpoint_nsÙ-generate:17a086c3-c037-25be-9512-a65b2286901f¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@f6e88680c041d683c3d6963c56e7e0c761f4e57970f7245c1498a5b6bc9aa351¢tsËAÚşp³Ô¨trace_idÙ$7c7176de-05c8-4d94-aa41-7f296cf35a17­parent_run_idÙ$6eddde57-d401-408e-b794-85dc6f672b5f¦run_idÙ$7c7176de-05c8-4d94-aa41-7f296cf35a17ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚ
messages=[HumanMessage(content="You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: What is LangChain and why was it created? \nContext: # Why LangChain?\n\nThe goal of `langchain` the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.\nWhile LangChain originally started as a single open source package, it has evolved into a company and a whole ecosystem.\nThis page will talk about the LangChain ecosystem as a whole.\nMost of the components within the LangChain ecosystem can be used by themselves - so if you feel particularly drawn to certain components but not others, that is totally fine! Pick and choose whichever components you like best for your own use case!\n\n## Features\n\nThere are several primary needs that LangChain aims to address:\n\n## Features\n\nThere are several primary needs that LangChain aims to address:\n\n1. **Standardized component interfaces:** The growing number of [models](/docs/integrations/chat/) and [related components](/docs/integrations/vectorstores/) for AI applications has resulted in a wide variety of different APIs that developers need to learn and use.\nThis diversity can make it challenging for developers to switch between providers or combine components when building applications.\nLangChain exposes a standard interface for key components, making it easy to switch between providers.\n\n---\nsidebar_position: 0\nsidebar_class_name: hidden\n---\n\n# Introduction\n\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\n\nLangChain simplifies every stage of the LLM application lifecycle:\n- **Development**: Build your applications using LangChain's open-source [components](/docs/concepts) and [third-party integrations](/docs/integrations/providers/).\nUse [LangGraph](/docs/concepts/architecture/#langgraph) to build stateful agents with first-class streaming and human-in-the-loop support.\n- **Productionization**: Use [LangSmith](https://docs.smith.langchain.com/) to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\n- **Deployment**: Turn your LangGraph applications into production-ready APIs and Assistants with [LangGraph Platform](https://langchain-ai.github.io/langgraph/cloud/).\n\nimport ThemedImage from '@theme/ThemedImage';\nimport useBaseUrl from '@docusaurus/useBaseUrl'; \nAnswer:", additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@4bc2c0780cad2d713b6eafe05e7d1080b8b0fe8580ed5bf74bf3e9c6fdea8b70¢tsËAÚşpñ;æ¨focus_msÍÃ§payload‚¤role©assistant§contentÚ–LangChain is a framework designed to help developers build applications powered by large language models (LLMs). It was created to simplify the development, productionization, and deployment of LLM applications by providing standardized component interfaces and a variety of tools within its ecosystem. This allows developers to easily switch between providers and integrate different components as needed.ªfocus_kind¬exec_latency¨query_id¤Q000‰¢idÙ@a023f1ae1188bf2032ef6e8e389884db365b9a4e94b188811df40abea381d50d¢tsËAÚşpñD¨trace_idÙ$6eddde57-d401-408e-b794-85dc6f672b5f­parent_run_idÙ$422f8817-09c0-4066-9b75-e004f1f783a2¦run_idÙ$6eddde57-d401-408e-b794-85dc6f672b5fªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ–LangChain is a framework designed to help developers build applications powered by large language models (LLMs). It was created to simplify the development, productionization, and deployment of LLM applications by providing standardized component interfaces and a variety of tools within its ecosystem. This allows developers to easily switch between providers and integrate different components as needed.¨query_id¤Q000ªfocus_kind¶chain_execution_result‹¢idÙ@ec28a681cf1bd1d114757a6245bc88f985e58e120ef4df1d7a989f793b43dc5f¢tsËAÚşpñQµ¨trace_id¤Q001­parent_run_idÀ¦run_idÙ$7ff19efe-95db-4298-9718-a862eda7613cªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ*Explain the role of an Agent in LangChain.¨query_id¤Q001§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q001ªfocus_kind¯chain_execution‹¢idÙ@b61255bbaaeb374a61b4d2d27773c22e9d9a7d41bf176a8f975f4c8e8cedf8ab¢tsËAÚşpñ_c¨trace_id¤Q001­parent_run_idÙ$7ff19efe-95db-4298-9718-a862eda7613c¦run_idÙ$296ca2ed-e110-4dc3-961a-7135a64b343fªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ*Explain the role of an Agent in LangChain.§context¦answer ¨query_id¤Q001¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q001®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:463bb712-9355-3ad5-0dbf-7aa1810b6e7bªfocus_kind¯chain_execution‰¢idÙ@2e4c08cf640c9977f4db4853f288971582a1e86878146efed00f9025ad08e156¢tsËAÚşqÛì¨trace_idÙ$b131f83b-3920-46d9-bc8f-66cc51639a5f­parent_run_idÙ$7ff19efe-95db-4298-9718-a862eda7613c¦run_idÙ$b131f83b-3920-46d9-bc8f-66cc51639a5fªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Agents

By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take ...¨metadata¦sourceÙE/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/agents.mdx‚´page_content_summaryÙË## Legacy agent concept: AgentExecutor

LangChain previously introduced the `AgentExecutor` as a runtime for agents. 
While it served as an excellent starting point, its limitations became apparent wh...¨metadata¦sourceÙE/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/agents.mdx‚´page_content_summaryÙË[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like incl...¨metadata¦sourceÙL/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/why_langchain.mdx¨query_id¤Q001¨questionÙ*Explain the role of an Agent in LangChain.ªfocus_kind¶chain_execution_result‹¢idÙ@4ca51553ece04d8085593e431518921a6550a60f98e45f6616b9413d6d6d73ca¢tsËAÚşq9ë¨trace_id¤Q001­parent_run_idÙ$0e41e79e-54ab-4cd9-9c49-6386840a5ccc¦run_idÙ$639f091e-e1bb-4325-8603-c57288b6ae10ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ*Explain the role of an Agent in LangChain.§contextÚ	\# Agents

By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.

[LangGraph](/docs/concepts/architecture#langgraph) is an extension of LangChain specifically aimed at creating highly controllable and customizable agents. We recommend that you use LangGraph for building agents.

Please see the following resources for more information:

* LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
* [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)

## Legacy agent concept: AgentExecutor

## Legacy agent concept: AgentExecutor

LangChain previously introduced the `AgentExecutor` as a runtime for agents. 
While it served as an excellent starting point, its limitations became apparent when dealing with more sophisticated and customized agents. 
As a result, we're gradually phasing out `AgentExecutor` in favor of more flexible solutions in LangGraph.

### Transitioning from AgentExecutor to langgraph

If you're currently using `AgentExecutor`, don't worry! We've prepared resources to help you:

1. For those who still need to use `AgentExecutor`, we offer a comprehensive guide on [how to use AgentExecutor](/docs/how_to/agent_executor).

2. However, we strongly recommend transitioning to LangGraph for improved flexibility and control. To facilitate this transition, we've created a detailed [migration guide](/docs/how_to/migrate_agent) to help you move from `AgentExecutor` to LangGraph seamlessly.

[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like including [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/), [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/), or [memory](https://langchain-ai.github.io/langgraph/concepts/memory/).

[LangSmith](https://docs.smith.langchain.com/) makes it possible to iterate with confidence on your applications, by providing LLM-specific observability and framework for testing and evaluating your application.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q001®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:080a5f85-8036-f28d-df97-b914bafe0c96­checkpoint_nsÙ-generate:080a5f85-8036-f28d-df97-b914bafe0c96¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@2f713b1b2311f91d699e6774db4fed4a7d0876807f49a1d622acdb5b251864c6¢tsËAÚşqR@¨trace_idÙ$639f091e-e1bb-4325-8603-c57288b6ae10­parent_run_idÙ$0e41e79e-54ab-4cd9-9c49-6386840a5ccc¦run_idÙ$639f091e-e1bb-4325-8603-c57288b6ae10ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚmessages=[HumanMessage(content="You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Explain the role of an Agent in LangChain. \nContext: # Agents\n\nBy themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.\n\n[LangGraph](/docs/concepts/architecture#langgraph) is an extension of LangChain specifically aimed at creating highly controllable and customizable agents. We recommend that you use LangGraph for building agents.\n\nPlease see the following resources for more information:\n\n* LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\n* [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)\n\n## Legacy agent concept: AgentExecutor\n\n## Legacy agent concept: AgentExecutor\n\nLangChain previously introduced the `AgentExecutor` as a runtime for agents. \nWhile it served as an excellent starting point, its limitations became apparent when dealing with more sophisticated and customized agents. \nAs a result, we're gradually phasing out `AgentExecutor` in favor of more flexible solutions in LangGraph.\n\n### Transitioning from AgentExecutor to langgraph\n\nIf you're currently using `AgentExecutor`, don't worry! We've prepared resources to help you:\n\n1. For those who still need to use `AgentExecutor`, we offer a comprehensive guide on [how to use AgentExecutor](/docs/how_to/agent_executor).\n\n2. However, we strongly recommend transitioning to LangGraph for improved flexibility and control. To facilitate this transition, we've created a detailed [migration guide](/docs/how_to/migrate_agent) to help you move from `AgentExecutor` to LangGraph seamlessly.\n\n[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) makes it possible to orchestrate complex applications (e.g., [agents](/docs/concepts/agents/)) and provide features like including [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/), [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/), or [memory](https://langchain-ai.github.io/langgraph/concepts/memory/).\n\n[LangSmith](https://docs.smith.langchain.com/) makes it possible to iterate with confidence on your applications, by providing LLM-specific observability and framework for testing and evaluating your application. \nAnswer:", additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@2222bc8110c23f1ccdc9c308cc1e525e72187d7cd1369b471d2ba4cb44a73fac¢tsËAÚşq_Å›¨focus_msÍ£§payload‚¤role©assistant§contentÚIn LangChain, an Agent acts as a system that takes a high-level task and utilizes a language model (LLM) as a reasoning engine to determine and execute the necessary actions. LangGraph is the recommended framework for building these agents, offering enhanced control and customization. The previous `AgentExecutor` is being phased out in favor of LangGraph for more sophisticated agent development.ªfocus_kind¬exec_latency¨query_id¤Q001‰¢idÙ@20ba42cf52942ad535897157e6d73ccc122329630fb50f17eb42af499e2ab766¢tsËAÚşq`$É¨trace_idÙ$0e41e79e-54ab-4cd9-9c49-6386840a5ccc­parent_run_idÙ$7ff19efe-95db-4298-9718-a862eda7613c¦run_idÙ$0e41e79e-54ab-4cd9-9c49-6386840a5cccªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚIn LangChain, an Agent acts as a system that takes a high-level task and utilizes a language model (LLM) as a reasoning engine to determine and execute the necessary actions. LangGraph is the recommended framework for building these agents, offering enhanced control and customization. The previous `AgentExecutor` is being phased out in favor of LangGraph for more sophisticated agent development.¨query_id¤Q001ªfocus_kind¶chain_execution_result‹¢idÙ@fa996c1a6b057fa4c4735953cfe975b6e797d7b6678e4e90a30e5aa39f7615c0¢tsËAÚşq`D³¨trace_id¤Q002­parent_run_idÀ¦run_idÙ$e4998b0b-9583-4050-9ed7-557d58bc9a24ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3How do I install LangChain with extras for tracing?¨query_id¤Q002§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q002ªfocus_kind¯chain_execution‹¢idÙ@f24e0fc60a9f69ff98cb27a2fde0b2a5953e208a54b47f5f766fdda6ceb14afb¢tsËAÚşq`º€¨trace_id¤Q002­parent_run_idÙ$e4998b0b-9583-4050-9ed7-557d58bc9a24¦run_idÙ$cf842bc6-9230-48a1-80ad-6c771234950dªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3How do I install LangChain with extras for tracing?§context¦answer ¨query_id¤Q002¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q002®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:149bb6de-3036-22e4-63c3-4f871b9f610bªfocus_kind¯chain_execution‰¢idÙ@49c8984f8dd5d5c8645fee4bc3d4f3508dd1170248d4a71a2f139b5579005a1f¢tsËAÚşqsÁ¨trace_idÙ$4f1b028e-f1ee-42db-a698-7a00ce355927­parent_run_idÙ$e4998b0b-9583-4050-9ed7-557d58bc9a24¦run_idÙ$4f1b028e-f1ee-42db-a698-7a00ce355927ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙÀ```bash
pip install -e .
```

LangGraph, LangSmith SDK, and certain integration packages live outside the main LangChain repo. You can see [all repos here](https://github.com/langchain-ai)....¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/installation.mdx‚´page_content_summaryÙË## Compatibility

LangChain is only compatible with the `asyncio` library, which is distributed as part of the Python standard library. It will not work with other async libraries like `trio` or `curi...¨metadata¦sourceÙD/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/async.mdx‚´page_content_summaryÙË---
sidebar_position: 2
---

# How to install LangChain packages

The LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of
functionality to install.
...¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/installation.mdx¨query_id¤Q002¨questionÙ3How do I install LangChain with extras for tracing?ªfocus_kind¶chain_execution_result‹¢idÙ@3dcc9310ac06e55bf55240bb5f4c3db67fb20ac79968777f00b260accb465edd¢tsËAÚşqsÕM¨trace_id¤Q002­parent_run_idÙ$d1699bb1-7992-4b2e-bd01-33b047e5aec1¦run_idÙ$a7d3f512-2577-443f-9c3f-f6858e2f9f03ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ3How do I install LangChain with extras for tracing?§contextÚC```bash
pip install -e .
```

LangGraph, LangSmith SDK, and certain integration packages live outside the main LangChain repo. You can see [all repos here](https://github.com/langchain-ai).

## Compatibility

LangChain is only compatible with the `asyncio` library, which is distributed as part of the Python standard library. It will not work with other async libraries like `trio` or `curio`.

In Python 3.9 and 3.10, [asyncio's tasks](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task) did not
accept a `context` parameter. Due to this limitation, LangChain cannot automatically propagate the `RunnableConfig` down the call chain
in certain scenarios.

If you are experiencing issues with streaming, callbacks or tracing in async code and are using Python 3.9 or 3.10, this is a likely cause.

Please read [Propagation RunnableConfig](/docs/concepts/runnables/#propagation-of-runnableconfig) for more details to learn how to propagate the `RunnableConfig` down the call chain manually (or upgrade to Python 3.11 where this is no longer an issue).

## How to use in ipython and jupyter notebooks

---
sidebar_position: 2
---

# How to install LangChain packages

The LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of
functionality to install.

## Official release

To install the main `langchain` package, run:

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from "@theme/CodeBlock";

<Tabs>
  <TabItem value="pip" label="Pip" default>
    <CodeBlock language="bash">pip install langchain</CodeBlock>
  </TabItem>
  <TabItem value="conda" label="Conda">
    <CodeBlock language="bash">conda install langchain -c conda-forge</CodeBlock>
  </TabItem>
</Tabs>

While this package acts as a sane starting point to using LangChain,
much of the value of LangChain comes when integrating it with various model providers, datastores, etc.
By default, the dependencies needed to do that are NOT installed. You will need to install the dependencies for specific integrations separately, which we show below.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q002®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:b2f840dc-dec4-43f8-a007-8deac6d28d62­checkpoint_nsÙ-generate:b2f840dc-dec4-43f8-a007-8deac6d28d62¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@b7168c53d560bafa75de2fdeef056f7fa06e034ad524bf11671a2d909d5a332a¢tsËAÚşqsé£¨trace_idÙ$a7d3f512-2577-443f-9c3f-f6858e2f9f03­parent_run_idÙ$d1699bb1-7992-4b2e-bd01-33b047e5aec1¦run_idÙ$a7d3f512-2577-443f-9c3f-f6858e2f9f03ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚ
messages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: How do I install LangChain with extras for tracing? \nContext: ```bash\npip install -e .\n```\n\nLangGraph, LangSmith SDK, and certain integration packages live outside the main LangChain repo. You can see [all repos here](https://github.com/langchain-ai).\n\n## Compatibility\n\nLangChain is only compatible with the `asyncio` library, which is distributed as part of the Python standard library. It will not work with other async libraries like `trio` or `curio`.\n\nIn Python 3.9 and 3.10, [asyncio\'s tasks](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task) did not\naccept a `context` parameter. Due to this limitation, LangChain cannot automatically propagate the `RunnableConfig` down the call chain\nin certain scenarios.\n\nIf you are experiencing issues with streaming, callbacks or tracing in async code and are using Python 3.9 or 3.10, this is a likely cause.\n\nPlease read [Propagation RunnableConfig](/docs/concepts/runnables/#propagation-of-runnableconfig) for more details to learn how to propagate the `RunnableConfig` down the call chain manually (or upgrade to Python 3.11 where this is no longer an issue).\n\n## How to use in ipython and jupyter notebooks\n\n---\nsidebar_position: 2\n---\n\n# How to install LangChain packages\n\nThe LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of\nfunctionality to install.\n\n## Official release\n\nTo install the main `langchain` package, run:\n\nimport Tabs from \'@theme/Tabs\';\nimport TabItem from \'@theme/TabItem\';\nimport CodeBlock from "@theme/CodeBlock";\n\n<Tabs>\n  <TabItem value="pip" label="Pip" default>\n    <CodeBlock language="bash">pip install langchain</CodeBlock>\n  </TabItem>\n  <TabItem value="conda" label="Conda">\n    <CodeBlock language="bash">conda install langchain -c conda-forge</CodeBlock>\n  </TabItem>\n</Tabs>\n\nWhile this package acts as a sane starting point to using LangChain,\nmuch of the value of LangChain comes when integrating it with various model providers, datastores, etc.\nBy default, the dependencies needed to do that are NOT installed. You will need to install the dependencies for specific integrations separately, which we show below. \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@0b7024d81aeadf304b06868c40257a26486d515c3fb1e724c3fd229313f80457¢tsËAÚşq±f•¨focus_msÍ¿§payload‚¤role©assistant§contentÚTo install LangChain with extras for tracing, you can use the command `pip install langchain[tracing]`. This will install the main LangChain package along with the additional dependencies required for tracing functionality. Make sure to check the specific integration packages if needed.ªfocus_kind¬exec_latency¨query_id¤Q002‰¢idÙ@4e5ac82d1411a02be2861174f3ac2379fcec6361b41a978a29b56efe57ec73a7¢tsËAÚşq±w¨trace_idÙ$d1699bb1-7992-4b2e-bd01-33b047e5aec1­parent_run_idÙ$e4998b0b-9583-4050-9ed7-557d58bc9a24¦run_idÙ$d1699bb1-7992-4b2e-bd01-33b047e5aec1ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚTo install LangChain with extras for tracing, you can use the command `pip install langchain[tracing]`. This will install the main LangChain package along with the additional dependencies required for tracing functionality. Make sure to check the specific integration packages if needed.¨query_id¤Q002ªfocus_kind¶chain_execution_result‹¢idÙ@40fac3495344d830e6b5da53349ad0de6b1294c679d50c57f82171950192ecb1¢tsËAÚşq±†ˆ¨trace_id¤Q003­parent_run_idÀ¦run_idÙ$943c060c-9673-4e0b-be4e-f6a9b4af774cªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ8Show the minimal LCEL chain that streams token-by-token.¨query_id¤Q003§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q003ªfocus_kind¯chain_execution‹¢idÙ@a534fbac05d794b71718b2c5bb78f2991fdbc1a44b71a32f609b66e02d51b8be¢tsËAÚşq±šˆ¨trace_id¤Q003­parent_run_idÙ$943c060c-9673-4e0b-be4e-f6a9b4af774c¦run_idÙ$bb40570c-9d07-4081-9a73-058dc4093950ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ8Show the minimal LCEL chain that streams token-by-token.§context¦answer ¨query_id¤Q003¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q003®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:5ca748c6-09eb-e4f4-424c-f7c80aa06b68ªfocus_kind¯chain_execution‰¢idÙ@8d8aa86f78f1e9dc96c59bac5f2a506ba5cd63835a6d05c92f37ab08be963fd0¢tsËAÚşqÃé¨trace_idÙ$ea0b6f22-4b6a-40c1-85ab-3a3e048dbf12­parent_run_idÙ$943c060c-9673-4e0b-be4e-f6a9b4af774c¦run_idÙ$ea0b6f22-4b6a-40c1-85ab-3a3e048dbf12ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË- **Simplify streaming**: LCEL chains can be streamed, allowing for incremental output as the chain is executed. LangChain can optimize the streaming of the output to minimize the time-to-first-token(...¨metadata¦sourceÙC/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/lcel.mdx‚´page_content_summaryÙËFor chains constructed using **LCEL**, the `.stream()` method only streams the output of the final step from the chain. This might be sufficient for some applications, but as you build more complex ch...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/streaming.mdx‚´page_content_summaryÙË# LangChain Expression Language (LCEL)

:::info Prerequisites
* [Runnable Interface](/docs/concepts/runnables)
:::

The **L**ang**C**hain **E**xpression **L**anguage (LCEL) takes a [declarative](https...¨metadata¦sourceÙC/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/lcel.mdx¨query_id¤Q003¨questionÙ8Show the minimal LCEL chain that streams token-by-token.ªfocus_kind¶chain_execution_result‹¢idÙ@5a856379c64dd7c57c94a3d250f5f49d5162d18b561191ea3e1451ae857cba80¢tsËAÚşqÄ¨trace_id¤Q003­parent_run_idÙ$bb730124-c7bc-4ce0-b4f3-bc1d9c1e13bf¦run_idÙ$c17dbc08-7c44-47cd-8a41-c2bca68bb63eªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ8Show the minimal LCEL chain that streams token-by-token.§contextÚ½- **Simplify streaming**: LCEL chains can be streamed, allowing for incremental output as the chain is executed. LangChain can optimize the streaming of the output to minimize the time-to-first-token(time elapsed until the first chunk of output from a [chat model](/docs/concepts/chat_models) or [llm](/docs/concepts/text_llms) comes out).

For chains constructed using **LCEL**, the `.stream()` method only streams the output of the final step from the chain. This might be sufficient for some applications, but as you build more complex chains of several LLM calls together, you may want to use the intermediate values of the chain alongside the final output. For example, you may want to return sources alongside the final generation when building a chat-over-documents app.

# LangChain Expression Language (LCEL)

:::info Prerequisites
* [Runnable Interface](/docs/concepts/runnables)
:::

The **L**ang**C**hain **E**xpression **L**anguage (LCEL) takes a [declarative](https://en.wikipedia.org/wiki/Declarative_programming) approach to building new [Runnables](/docs/concepts/runnables) from existing Runnables.

This means that you describe what *should* happen, rather than *how* it should happen, allowing LangChain to optimize the run-time execution of the chains.

We often refer to a `Runnable` created using LCEL as a "chain". It's important to remember that a "chain" is `Runnable` and it implements the full [Runnable Interface](/docs/concepts/runnables).¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q003®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:d595aa48-ee8e-5fd2-19a3-37ae9b58a8a4­checkpoint_nsÙ-generate:d595aa48-ee8e-5fd2-19a3-37ae9b58a8a4¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@a7dc28a5d79140dd04459a21f30ec37b6d7913104e450750ad50c604324cda29¢tsËAÚşqÄ2²¨trace_idÙ$c17dbc08-7c44-47cd-8a41-c2bca68bb63e­parent_run_idÙ$bb730124-c7bc-4ce0-b4f3-bc1d9c1e13bf¦run_idÙ$c17dbc08-7c44-47cd-8a41-c2bca68bb63eªevent_type¬chain_output¬event_source¥chain§payload§outputsÚdmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Show the minimal LCEL chain that streams token-by-token. \nContext: - **Simplify streaming**: LCEL chains can be streamed, allowing for incremental output as the chain is executed. LangChain can optimize the streaming of the output to minimize the time-to-first-token(time elapsed until the first chunk of output from a [chat model](/docs/concepts/chat_models) or [llm](/docs/concepts/text_llms) comes out).\n\nFor chains constructed using **LCEL**, the `.stream()` method only streams the output of the final step from the chain. This might be sufficient for some applications, but as you build more complex chains of several LLM calls together, you may want to use the intermediate values of the chain alongside the final output. For example, you may want to return sources alongside the final generation when building a chat-over-documents app.\n\n# LangChain Expression Language (LCEL)\n\n:::info Prerequisites\n* [Runnable Interface](/docs/concepts/runnables)\n:::\n\nThe **L**ang**C**hain **E**xpression **L**anguage (LCEL) takes a [declarative](https://en.wikipedia.org/wiki/Declarative_programming) approach to building new [Runnables](/docs/concepts/runnables) from existing Runnables.\n\nThis means that you describe what *should* happen, rather than *how* it should happen, allowing LangChain to optimize the run-time execution of the chains.\n\nWe often refer to a `Runnable` created using LCEL as a "chain". It\'s important to remember that a "chain" is `Runnable` and it implements the full [Runnable Interface](/docs/concepts/runnables). \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@8c88ff3920832eb4fb4ba055a84c926d9b93010915b86f637fba42cdd2a331d3¢tsËAÚşr—–¨focus_msÍ§payload‚¤role©assistant§contentÚTThe minimal LCEL chain that streams token-by-token can be created using the `.stream()` method, which streams the output of the final step in the chain. This allows for incremental output as the chain executes, optimizing the time-to-first-token. For more complex applications, consider using intermediate values alongside the final output.ªfocus_kind¬exec_latency¨query_id¤Q003‰¢idÙ@a1028d2ed3380e4d9ae49b500de41c7cec7921db460685d25e3ce9c075a9fc4d¢tsËAÚşr­ø¨trace_idÙ$bb730124-c7bc-4ce0-b4f3-bc1d9c1e13bf­parent_run_idÙ$943c060c-9673-4e0b-be4e-f6a9b4af774c¦run_idÙ$bb730124-c7bc-4ce0-b4f3-bc1d9c1e13bfªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚTThe minimal LCEL chain that streams token-by-token can be created using the `.stream()` method, which streams the output of the final step in the chain. This allows for incremental output as the chain executes, optimizing the time-to-first-token. For more complex applications, consider using intermediate values alongside the final output.¨query_id¤Q003ªfocus_kind¶chain_execution_result‹¢idÙ@b45f2ea900bd7c9f35b0bd9718c371b328449e69c43292af5d7aceedcc5f0ca4¢tsËAÚşrÀù¨trace_id¤Q004­parent_run_idÀ¦run_idÙ$69b0c6b3-794a-4c44-aebe-f35e597bc7fdªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.¨query_id¤Q004§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q004ªfocus_kind¯chain_execution‹¢idÙ@d14330467cda56bc449d9bae005b9bade558351c0b848d125f0007237c9ba728¢tsËAÚşrâ›¨trace_id¤Q004­parent_run_idÙ$69b0c6b3-794a-4c44-aebe-f35e597bc7fd¦run_idÙ$01fd2ffe-40cd-42c0-87f2-9906d1a90997ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.§context¦answer ¨query_id¤Q004¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q004®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:805054e9-6e43-bcb7-10a7-c9b3052c8aa7ªfocus_kind¯chain_execution‰¢idÙ@c9e964021506206c2d1aad0c12dbbfade46acb6c167381ff5fee673b83d31cbe¢tsËAÚşrª¨trace_idÙ$bd4603d2-9720-45ab-be07-7a0cdb7a5328­parent_run_idÙ$69b0c6b3-794a-4c44-aebe-f35e597bc7fd¦run_idÙ$bd4603d2-9720-45ab-be07-7a0cdb7a5328ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙËThere are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.


<Tabs>
  <TabIt...¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/vectorstores.mdx‚´page_content_summaryÙË:::

### Similarity search

Given a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over *all* the embedded d...¨metadata¦sourceÙK/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/vectorstores.mdx‚´page_content_summaryÙË```python
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="lance" label="Lance">

This notebook shows ho...¨metadata¦sourceÙI/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/vectorstores.mdx¨query_id¤Q004¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.ªfocus_kind¶chain_execution_result‹¢idÙ@6fff80d22e86e5663eb5e071497d88d546b82cb7f40b85f610b16650fbf0ec0a¢tsËAÚşrß¨trace_id¤Q004­parent_run_idÙ$ff713641-ab2f-4326-8662-13a153b91ba4¦run_idÙ$6812fc74-7f56-488e-82f1-53bc6f8f5a72ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ4Compare FAISS and Chroma vector stores in LangChain.§contextÚ
ØThere are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.


<Tabs>
  <TabItem value="chroma" label="Chroma" default>

This walkthrough uses the `chroma` vector database, which runs on your local machine as a library.

```bash
pip install langchain-chroma
```

```python
from langchain_chroma import Chroma

db = Chroma.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="faiss" label="FAISS">

This walkthrough uses the `FAISS` vector database, which makes use of the Facebook AI Similarity Search (FAISS) library.

```bash
pip install faiss-cpu
```

```python
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="lance" label="Lance">

:::

### Similarity search

Given a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over *all* the embedded documents to find the most similar ones.
There are various ways to do this. As an example, many vectorstores implement [HNSW (Hierarchical Navigable Small World)](https://www.pinecone.io/learn/series/faiss/hnsw/), a graph-based index structure that allows for efficient similarity search.
Regardless of the search algorithm used under the hood, the LangChain vectorstore interface has a `similarity_search` method for all integrations. 
This will take the search query, create an embedding, find similar documents, and return them as a list of [Documents](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html).

```python
query = "my query"
docs = vectorstore.similarity_search(query)
```

```python
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
  <TabItem value="lance" label="Lance">

This notebook shows how to use functionality related to the LanceDB vector database based on the Lance data format.

```bash
pip install lancedb
```

```python
from langchain_community.vectorstores import LanceDB

import lancedb

db = lancedb.connect("/tmp/lancedb")
table = db.create_table(
    "my_table",
    data=[
        {
            "vector": embeddings.embed_query("Hello World"),
            "text": "Hello World",
            "id": "1",
        }
    ],
    mode="overwrite",
)
db = LanceDB.from_documents(documents, OpenAIEmbeddings())
```

  </TabItem>
</Tabs>


## Similarity search

All vectorstores expose a `similarity_search` method.
This will take incoming documents, create an embedding of them, and then find all documents with the most similar embedding.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q004®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:e502daa9-a5ea-6787-802f-c996fccfdda1­checkpoint_nsÙ-generate:e502daa9-a5ea-6787-802f-c996fccfdda1¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@edbe799d6f62363148e76c1fec2d4dcc5078ac70370a5e4f6218fc9bdc2cde90¢tsËAÚşrìò¨trace_idÙ$6812fc74-7f56-488e-82f1-53bc6f8f5a72­parent_run_idÙ$ff713641-ab2f-4326-8662-13a153b91ba4¦run_idÙ$6812fc74-7f56-488e-82f1-53bc6f8f5a72ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚÈmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Compare FAISS and Chroma vector stores in LangChain. \nContext: There are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.\n\n\n<Tabs>\n  <TabItem value="chroma" label="Chroma" default>\n\nThis walkthrough uses the `chroma` vector database, which runs on your local machine as a library.\n\n```bash\npip install langchain-chroma\n```\n\n```python\nfrom langchain_chroma import Chroma\n\ndb = Chroma.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n  <TabItem value="faiss" label="FAISS">\n\nThis walkthrough uses the `FAISS` vector database, which makes use of the Facebook AI Similarity Search (FAISS) library.\n\n```bash\npip install faiss-cpu\n```\n\n```python\nfrom langchain_community.vectorstores import FAISS\n\ndb = FAISS.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n  <TabItem value="lance" label="Lance">\n\n:::\n\n### Similarity search\n\nGiven a similarity metric to measure the distance between the embedded query and any embedded document, we need an algorithm to efficiently search over *all* the embedded documents to find the most similar ones.\nThere are various ways to do this. As an example, many vectorstores implement [HNSW (Hierarchical Navigable Small World)](https://www.pinecone.io/learn/series/faiss/hnsw/), a graph-based index structure that allows for efficient similarity search.\nRegardless of the search algorithm used under the hood, the LangChain vectorstore interface has a `similarity_search` method for all integrations. \nThis will take the search query, create an embedding, find similar documents, and return them as a list of [Documents](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html).\n\n```python\nquery = "my query"\ndocs = vectorstore.similarity_search(query)\n```\n\n```python\nfrom langchain_community.vectorstores import FAISS\n\ndb = FAISS.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n  <TabItem value="lance" label="Lance">\n\nThis notebook shows how to use functionality related to the LanceDB vector database based on the Lance data format.\n\n```bash\npip install lancedb\n```\n\n```python\nfrom langchain_community.vectorstores import LanceDB\n\nimport lancedb\n\ndb = lancedb.connect("/tmp/lancedb")\ntable = db.create_table(\n    "my_table",\n    data=[\n        {\n            "vector": embeddings.embed_query("Hello World"),\n            "text": "Hello World",\n            "id": "1",\n        }\n    ],\n    mode="overwrite",\n)\ndb = LanceDB.from_documents(documents, OpenAIEmbeddings())\n```\n\n  </TabItem>\n</Tabs>\n\n\n## Similarity search\n\nAll vectorstores expose a `similarity_search` method.\nThis will take incoming documents, create an embedding of them, and then find all documents with the most similar embedding. \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@717290a99df9d190cfa893e2085baf351d78533e15f7b486d18e95a85debfb45¢tsËAÚşr`eú¨focus_msÍL§payload‚¤role©assistant§contentÚ!FAISS and Chroma are both vector stores that can run locally and are integrated with LangChain. FAISS utilizes the Facebook AI Similarity Search library, while Chroma operates as a standalone library. Both support a `similarity_search` method to find similar documents based on embeddings.ªfocus_kind¬exec_latency¨query_id¤Q004‰¢idÙ@71bfa4e6337d26e883122e8110b9cb9754b4206af9710637d1583364ff53c59b¢tsËAÚşr`w’¨trace_idÙ$ff713641-ab2f-4326-8662-13a153b91ba4­parent_run_idÙ$69b0c6b3-794a-4c44-aebe-f35e597bc7fd¦run_idÙ$ff713641-ab2f-4326-8662-13a153b91ba4ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ!FAISS and Chroma are both vector stores that can run locally and are integrated with LangChain. FAISS utilizes the Facebook AI Similarity Search library, while Chroma operates as a standalone library. Both support a `similarity_search` method to find similar documents based on embeddings.¨query_id¤Q004ªfocus_kind¶chain_execution_result‹¢idÙ@b1821da8018bdf54e4040026499452677f239594c87d5cee941453cd39de946a¢tsËAÚşr`ˆ¤¨trace_id¤Q005­parent_run_idÀ¦run_idÙ$13b0738d-f44c-4788-b031-65ee6941b0f8ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?¨query_id¤Q005§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q005ªfocus_kind¯chain_execution‹¢idÙ@0dd334f3faceb5ee77e520a0b9555d8758a28d5d086c0ffb24dfa2c8dc293e9a¢tsËAÚşr`¯â¨trace_id¤Q005­parent_run_idÙ$13b0738d-f44c-4788-b031-65ee6941b0f8¦run_idÙ$a722e1e8-dbe7-4529-b8d2-890f35c8f47fªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?§context¦answer ¨query_id¤Q005¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q005®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:18dcae7d-2def-ec98-62bd-1202dba2b327ªfocus_kind¯chain_execution‰¢idÙ@90d56b2f31f66a04e6617bc4381f5313b60681b3f01834442e34ec98179324d6¢tsËAÚşrwï„¨trace_idÙ$ae7a352c-4cb7-4ba1-a9f5-a506e21d5653­parent_run_idÙ$13b0738d-f44c-4788-b031-65ee6941b0f8¦run_idÙ$ae7a352c-4cb7-4ba1-a9f5-a506e21d5653ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# How to load Microsoft Office files

The [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, ...¨metadata¦sourceÙX/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/document_loader_office_file.mdx‚´page_content_summaryÙË## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader

[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known as `Azure Form Recognizer`) is machine-learning 
b...¨metadata¦sourceÙX/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/document_loader_office_file.mdx‚´page_content_summaryÙË### Prerequisite

An Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-s...¨metadata¦sourceÙX/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/document_loader_office_file.mdx¨query_id¤Q005¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?ªfocus_kind¶chain_execution_result‹¢idÙ@3359b50452b2c07be9c4e3e8bec947d8c9ee58785a4290ea475bca1dc49aa41e¢tsËAÚşrxœ¨trace_id¤Q005­parent_run_idÙ$ac17a012-e23c-4a76-a902-c05baa4a8046¦run_idÙ$34e378f6-9075-4f9d-9161-06d2f53607b7ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙCHow can I load a Microsoft Word document into a LangChain pipeline?§contextÚ	°# How to load Microsoft Office files

The [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.

This covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a LangChain 
[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document)
object that we can use downstream.


## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader

## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader

[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known as `Azure Form Recognizer`) is machine-learning 
based service that extracts texts (including handwriting), tables, document structures (e.g., titles, section headings, etc.) and key-value-pairs from
digital or scanned PDFs, images, Office and HTML files. Document Intelligence supports `PDF`, `JPEG/JPG`, `PNG`, `BMP`, `TIFF`, `HEIF`, `DOCX`, `XLSX`, `PPTX` and `HTML`.

This [current implementation](https://aka.ms/di-langchain) of a loader using `Document Intelligence` can incorporate content page-wise and turn it into LangChain documents. The default output format is markdown, which can be easily chained with `MarkdownHeaderTextSplitter` for semantic document chunking. You can also use `mode="single"` or `mode="page"` to return pure texts in a single page or document split by page.

### Prerequisite

### Prerequisite

An Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don't have. You will be passing `<endpoint>` and `<key>` as parameters to the loader.

```python
%pip install --upgrade --quiet  langchain langchain-community azure-ai-documentintelligence

from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader

file_path = "<filepath>"
endpoint = "<endpoint>"
key = "<key>"
loader = AzureAIDocumentIntelligenceLoader(
    api_endpoint=endpoint, api_key=key, file_path=file_path, api_model="prebuilt-layout"
)

documents = loader.load()
```¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q005®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:79df02c4-327d-ec24-9ea3-7b0a426663c6­checkpoint_nsÙ-generate:79df02c4-327d-ec24-9ea3-7b0a426663c6¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@7ce7a5ba1aba9d3d4d7f1b9ab8be874d55b0b23616b033ec5601f1d0c72a1d3a¢tsËAÚşrx+Ç¨trace_idÙ$34e378f6-9075-4f9d-9161-06d2f53607b7­parent_run_idÙ$ac17a012-e23c-4a76-a902-c05baa4a8046¦run_idÙ$34e378f6-9075-4f9d-9161-06d2f53607b7ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚzmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: How can I load a Microsoft Word document into a LangChain pipeline? \nContext: # How to load Microsoft Office files\n\nThe [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n\nThis covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a LangChain \n[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document)\nobject that we can use downstream.\n\n\n## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader\n\n## Loading DOCX, XLSX, PPTX with AzureAIDocumentIntelligenceLoader\n\n[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known as `Azure Form Recognizer`) is machine-learning \nbased service that extracts texts (including handwriting), tables, document structures (e.g., titles, section headings, etc.) and key-value-pairs from\ndigital or scanned PDFs, images, Office and HTML files. Document Intelligence supports `PDF`, `JPEG/JPG`, `PNG`, `BMP`, `TIFF`, `HEIF`, `DOCX`, `XLSX`, `PPTX` and `HTML`.\n\nThis [current implementation](https://aka.ms/di-langchain) of a loader using `Document Intelligence` can incorporate content page-wise and turn it into LangChain documents. The default output format is markdown, which can be easily chained with `MarkdownHeaderTextSplitter` for semantic document chunking. You can also use `mode="single"` or `mode="page"` to return pure texts in a single page or document split by page.\n\n### Prerequisite\n\n### Prerequisite\n\nAn Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don\'t have. You will be passing `<endpoint>` and `<key>` as parameters to the loader.\n\n```python\n%pip install --upgrade --quiet  langchain langchain-community azure-ai-documentintelligence\n\nfrom langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n\nfile_path = "<filepath>"\nendpoint = "<endpoint>"\nkey = "<key>"\nloader = AzureAIDocumentIntelligenceLoader(\n    api_endpoint=endpoint, api_key=key, file_path=file_path, api_model="prebuilt-layout"\n)\n\ndocuments = loader.load()\n``` \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@c49acbe76df2cce4819db06904052c31835108efbd82a984a7ef22e145b795fd¢tsËAÚşs Ç}¨focus_msÍU§payload‚¤role©assistant§contentÚYTo load a Microsoft Word document into a LangChain pipeline, you can use the `AzureAIDocumentIntelligenceLoader`. First, ensure you have an Azure AI Document Intelligence resource set up, then use the loader with your file path, endpoint, and key to load the document. The code snippet provided in the context demonstrates how to implement this.ªfocus_kind¬exec_latency¨query_id¤Q005‰¢idÙ@7549d97bc8b81ba9fbbd9bc91fa5e705a009996ca38160bb59bb5a9cd3c65132¢tsËAÚşs!¨trace_idÙ$ac17a012-e23c-4a76-a902-c05baa4a8046­parent_run_idÙ$13b0738d-f44c-4788-b031-65ee6941b0f8¦run_idÙ$ac17a012-e23c-4a76-a902-c05baa4a8046ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚYTo load a Microsoft Word document into a LangChain pipeline, you can use the `AzureAIDocumentIntelligenceLoader`. First, ensure you have an Azure AI Document Intelligence resource set up, then use the loader with your file path, endpoint, and key to load the document. The code snippet provided in the context demonstrates how to implement this.¨query_id¤Q005ªfocus_kind¶chain_execution_result‹¢idÙ@5e5e62e5728802160b2d3c04f2af5548526ec2ab26af4bc0db4c4da6aab8838a¢tsËAÚşs,€¨trace_id¤Q006­parent_run_idÀ¦run_idÙ$7d8be47f-167b-47e1-a4d2-43077d0b86f6ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ2Describe the Runnable protocol and its advantages.¨query_id¤Q006§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q006ªfocus_kind¯chain_execution‹¢idÙ@8ce3c62a43ef820e6322c8e6e711ee03a211ab33865270e69e3e3fac05c1f473¢tsËAÚşsO~¨trace_id¤Q006­parent_run_idÙ$7d8be47f-167b-47e1-a4d2-43077d0b86f6¦run_idÙ$a43fc99b-6240-4bdb-9d9f-5706900fa3e6ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ2Describe the Runnable protocol and its advantages.§context¦answer ¨query_id¤Q006¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q006®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:2e372d65-faa4-616e-18af-697e57b20b4eªfocus_kind¯chain_execution‰¢idÙ@748fba7acf684a1e998a7190cc92f0699d0f649169a3459c1a82cb6cc5a5bad2¢tsËAÚşséå¨trace_idÙ$443cb4e4-fdff-4594-b732-6aebee60f22d­parent_run_idÙ$7d8be47f-167b-47e1-a4d2-43077d0b86f6¦run_idÙ$443cb4e4-fdff-4594-b732-6aebee60f22dªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Runnable interface

The Runnable interface is the foundation for working with LangChain components, and it's implemented across many of them, such as [language models](/docs/concepts/chat_models), [...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/runnables.mdx‚´page_content_summaryÙË## Overview of runnable interface

The Runnable way defines a standard interface that allows a Runnable component to be:

* [Invoked](/docs/how_to/lcel_cheatsheet/#invoke-a-runnable): A single input i...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/runnables.mdx‚´page_content_summaryÙËThis guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.

:::info Relate...¨metadata¦sourceÙH/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/runnables.mdx¨query_id¤Q006¨questionÙ2Describe the Runnable protocol and its advantages.ªfocus_kind¶chain_execution_result‹¢idÙ@822aad57ce890b3c2676f56203ee570425e9b4fab1c8240a7b9870abbe28af42¢tsËAÚşs¸¨trace_id¤Q006­parent_run_idÙ$c7ff5f2d-3d2a-41c7-b11f-2d2815efeae0¦run_idÙ$248c0912-0b78-4458-b632-93e74f7c4c15ªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ2Describe the Runnable protocol and its advantages.§contextÚ	£# Runnable interface

The Runnable interface is the foundation for working with LangChain components, and it's implemented across many of them, such as [language models](/docs/concepts/chat_models), [output parsers](/docs/concepts/output_parsers), [retrievers](/docs/concepts/retrievers), [compiled LangGraph graphs](
https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) and more.

This guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.

## Overview of runnable interface

The Runnable way defines a standard interface that allows a Runnable component to be:

* [Invoked](/docs/how_to/lcel_cheatsheet/#invoke-a-runnable): A single input is transformed into an output.
* [Batched](/docs/how_to/lcel_cheatsheet/#batch-a-runnable): Multiple inputs are efficiently transformed into outputs.
* [Streamed](/docs/how_to/lcel_cheatsheet/#stream-a-runnable): Outputs are streamed as they are produced.
* Inspected: Schematic information about Runnable's input, output, and configuration can be accessed.
* Composed: Multiple Runnables can be composed to work together using [the LangChain Expression Language (LCEL)](/docs/concepts/lcel) to create complex pipelines.

Please review the [LCEL Cheatsheet](/docs/how_to/lcel_cheatsheet) for some common patterns that involve the Runnable interface and LCEL expressions.

<a id="batch"></a>
### Optimized parallel execution (batch)
<span data-heading-keywords="batch"></span>

This guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.

:::info Related Resources
* The ["Runnable" Interface API Reference](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) provides a detailed overview of the Runnable interface and its methods.
* A list of built-in `Runnables` can be found in the [LangChain Core API Reference](https://python.langchain.com/api_reference/core/runnables.html). Many of these Runnables are useful when composing custom "chains" in LangChain using the [LangChain Expression Language (LCEL)](/docs/concepts/lcel).
:::

## Overview of runnable interface

The Runnable way defines a standard interface that allows a Runnable component to be:¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q006®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:4645957b-a8ee-013a-1828-0815f099774a­checkpoint_nsÙ-generate:4645957b-a8ee-013a-1828-0815f099774a¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@e5ccaa47b0e7c9c465ee407412c6b866df5f530a0327ce1e5dc435df07e828ca¢tsËAÚşsü¨trace_idÙ$248c0912-0b78-4458-b632-93e74f7c4c15­parent_run_idÙ$c7ff5f2d-3d2a-41c7-b11f-2d2815efeae0¦run_idÙ$248c0912-0b78-4458-b632-93e74f7c4c15ªevent_type¬chain_output¬event_source¥chain§payload§outputsÚWmessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: Describe the Runnable protocol and its advantages. \nContext: # Runnable interface\n\nThe Runnable interface is the foundation for working with LangChain components, and it\'s implemented across many of them, such as [language models](/docs/concepts/chat_models), [output parsers](/docs/concepts/output_parsers), [retrievers](/docs/concepts/retrievers), [compiled LangGraph graphs](\nhttps://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) and more.\n\nThis guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.\n\n## Overview of runnable interface\n\nThe Runnable way defines a standard interface that allows a Runnable component to be:\n\n* [Invoked](/docs/how_to/lcel_cheatsheet/#invoke-a-runnable): A single input is transformed into an output.\n* [Batched](/docs/how_to/lcel_cheatsheet/#batch-a-runnable): Multiple inputs are efficiently transformed into outputs.\n* [Streamed](/docs/how_to/lcel_cheatsheet/#stream-a-runnable): Outputs are streamed as they are produced.\n* Inspected: Schematic information about Runnable\'s input, output, and configuration can be accessed.\n* Composed: Multiple Runnables can be composed to work together using [the LangChain Expression Language (LCEL)](/docs/concepts/lcel) to create complex pipelines.\n\nPlease review the [LCEL Cheatsheet](/docs/how_to/lcel_cheatsheet) for some common patterns that involve the Runnable interface and LCEL expressions.\n\n<a id="batch"></a>\n### Optimized parallel execution (batch)\n<span data-heading-keywords="batch"></span>\n\nThis guide covers the main concepts and methods of the Runnable interface, which allows developers to interact with various LangChain components in a consistent and predictable manner.\n\n:::info Related Resources\n* The ["Runnable" Interface API Reference](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) provides a detailed overview of the Runnable interface and its methods.\n* A list of built-in `Runnables` can be found in the [LangChain Core API Reference](https://python.langchain.com/api_reference/core/runnables.html). Many of these Runnables are useful when composing custom "chains" in LangChain using the [LangChain Expression Language (LCEL)](/docs/concepts/lcel).\n:::\n\n## Overview of runnable interface\n\nThe Runnable way defines a standard interface that allows a Runnable component to be: \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@b3605b97c137bbfe44568fb1cc3de4b2258646cd5ba9bd74802d11b3d1730dff¢tsËAÚşsaú±¨focus_msÍÎ§payload‚¤role©assistant§contentÚ–The Runnable protocol is a standard interface in LangChain that allows components to be invoked, batched, streamed, inspected, and composed. Its advantages include consistent interaction with various components, efficient processing of multiple inputs, and the ability to create complex pipelines through composition. This enhances flexibility and predictability in developing applications using LangChain.ªfocus_kind¬exec_latency¨query_id¤Q006‰¢idÙ@7402a1df8600b22612c508716af88eece89d475225b77742a3336e5a86ae6e61¢tsËAÚşsb	¨trace_idÙ$c7ff5f2d-3d2a-41c7-b11f-2d2815efeae0­parent_run_idÙ$7d8be47f-167b-47e1-a4d2-43077d0b86f6¦run_idÙ$c7ff5f2d-3d2a-41c7-b11f-2d2815efeae0ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚ–The Runnable protocol is a standard interface in LangChain that allows components to be invoked, batched, streamed, inspected, and composed. Its advantages include consistent interaction with various components, efficient processing of multiple inputs, and the ability to create complex pipelines through composition. This enhances flexibility and predictability in developing applications using LangChain.¨query_id¤Q006ªfocus_kind¶chain_execution_result‹¢idÙ@bfab6eb5fceeca62157239c9d03f576f2733e5fcdc13eae1430b10f9b5b3768b¢tsËAÚşsb ¨trace_id¤Q007­parent_run_idÀ¦run_idÙ$d2c9e0cc-d053-41ef-9e50-8d8ff5dd49c4ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3What is Few-Shot prompting and how is it supported?¨query_id¤Q007§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q007ªfocus_kind¯chain_execution‹¢idÙ@b53b82cde5af7bb1971f55860f67cfd1231424675f1b070aea788460de8c827b¢tsËAÚşsb[Š¨trace_id¤Q007­parent_run_idÙ$d2c9e0cc-d053-41ef-9e50-8d8ff5dd49c4¦run_idÙ$afb253b6-a1b6-41d3-be9f-efb9f42db706ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ3What is Few-Shot prompting and how is it supported?§context¦answer ¨query_id¤Q007¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q007®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:6e320938-b33d-06d4-768d-3e83bd38db55ªfocus_kind¯chain_execution‰¢idÙ@45670cd1f3f3646528529fa0caed2ce952dbdb3da7fe8ac3b40bc83128872458¢tsËAÚşs{*¨trace_idÙ$c98c3d04-5673-45b8-b014-22fa72df93d9­parent_run_idÙ$d2c9e0cc-d053-41ef-9e50-8d8ff5dd49c4¦run_idÙ$c98c3d04-5673-45b8-b014-22fa72df93d9ªevent_type¬chain_output¬event_source¥chain§payload§outputsƒ§context“‚´page_content_summaryÙË# Few-shot prompting

:::note Prerequisites

- [Chat models](/docs/concepts/chat_models/)
:::

## Overview

One of the most effective ways to improve model performance is to give a model examples of
w...¨metadata¦sourceÙQ/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/few_shot_prompting.mdx‚´page_content_summaryÙËThese requirements are model-specific and should be checked for the model you are using. If your model requires ToolMessages after tool calls and/or AIMessages after ToolMessages and your examples onl...¨metadata¦sourceÙQ/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/concepts/few_shot_prompting.mdx‚´page_content_summaryÙË### Example selectors

[Example Selectors](/docs/concepts/example_selectors) are responsible for selecting the correct few shot examples to pass to the prompt.

- [How to: use example selectors](/docs...¨metadata¦sourceÙB/Users/manirashahmadi/ccode/aep/aep-sdk/docs/docs/how_to/index.mdx¨query_id¤Q007¨questionÙ3What is Few-Shot prompting and how is it supported?ªfocus_kind¶chain_execution_result‹¢idÙ@2329f5241e00efcd4d8218a97302e76d8dd4f050c10df8c38b02429a6b023015¢tsËAÚşs{%ÿ¨trace_id¤Q007­parent_run_idÙ$ebbc14f6-86f0-41dc-8751-3f7cb8d308e4¦run_idÙ$2066ba82-6f84-42bc-a688-d52268f7ccaeªevent_type«chain_start¬event_source²ChatPromptTemplate§payload‚¦inputs‚¨questionÙ3What is Few-Shot prompting and how is it supported?§contextÚ
6# Few-shot prompting

:::note Prerequisites

- [Chat models](/docs/concepts/chat_models/)
:::

## Overview

One of the most effective ways to improve model performance is to give a model examples of
what you want it to do. The technique of adding example inputs and expected outputs
to a model prompt is known as "few-shot prompting". The technique is based on the
[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) paper.
There are a few things to think about when doing few-shot prompting:

1. How are examples generated?
2. How many examples are in each prompt?
3. How are examples selected at runtime?
4. How are examples formatted in the prompt?

Here are the considerations for each.

## 1. Generating examples

The first and most important step of few-shot prompting is coming up with a good dataset of examples. Good examples should be relevant at runtime, clear, informative, and provide information that was not already known to the model.

These requirements are model-specific and should be checked for the model you are using. If your model requires ToolMessages after tool calls and/or AIMessages after ToolMessages and your examples only include expected tool calls and not the actual tool outputs, you can try adding dummy ToolMessages / AIMessages to the end of each example with generic contents to satisfy the API constraints.
In these cases it's especially worth experimenting with inserting your examples as strings versus messages, as having dummy messages can adversely affect certain models.

You can see a case study of how Anthropic and OpenAI respond to different few-shot prompting techniques on two different tool calling benchmarks [here](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/).

### Example selectors

[Example Selectors](/docs/concepts/example_selectors) are responsible for selecting the correct few shot examples to pass to the prompt.

- [How to: use example selectors](/docs/how_to/example_selectors)
- [How to: select examples by length](/docs/how_to/example_selectors_length_based)
- [How to: select examples by semantic similarity](/docs/how_to/example_selectors_similarity)
- [How to: select examples by semantic ngram overlap](/docs/how_to/example_selectors_ngram)
- [How to: select examples by maximal marginal relevance](/docs/how_to/example_selectors_mmr)
- [How to: select examples from LangSmith few-shot datasets](/docs/how_to/example_selectors_langsmith/)

### LLMs

What LangChain calls [LLMs](/docs/concepts/text_llms) are older forms of language models that take a string in and output a string.¯serialized_repr§summaryÚ Serialized object too long, starts with: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['context', 'question'], 'metadata': {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, 'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'pro...¤tags‘ªseq:step:1¨metadataŠ¨query_id¤Q007®langgraph_step®langgraph_node¨generate²langgraph_triggers‘²branch:to:generate®langgraph_path’­__pregel_pull¨generate·langgraph_checkpoint_nsÙ-generate:6a37a3f4-6843-20c4-4c57-84cd6339913d­checkpoint_nsÙ-generate:6a37a3f4-6843-20c4-4c57-84cd6339913d¬lc_hub_owner£rlm«lc_hub_repoªrag-prompt²lc_hub_commit_hashÙ@50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6eªfocus_kind¯chain_execution‰¢idÙ@2e584a1e61b03b42149fa4a99d7534bf0e3b4aa6be58c8bb307facba2008b0f8¢tsËAÚşs{L”¨trace_idÙ$2066ba82-6f84-42bc-a688-d52268f7ccae­parent_run_idÙ$ebbc14f6-86f0-41dc-8751-3f7cb8d308e4¦run_idÙ$2066ba82-6f84-42bc-a688-d52268f7ccaeªevent_type¬chain_output¬event_source¥chain§payload§outputsÚömessages=[HumanMessage(content='You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\'t know the answer, just say that you don\'t know. Use three sentences maximum and keep the answer concise.\nQuestion: What is Few-Shot prompting and how is it supported? \nContext: # Few-shot prompting\n\n:::note Prerequisites\n\n- [Chat models](/docs/concepts/chat_models/)\n:::\n\n## Overview\n\nOne of the most effective ways to improve model performance is to give a model examples of\nwhat you want it to do. The technique of adding example inputs and expected outputs\nto a model prompt is known as "few-shot prompting". The technique is based on the\n[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) paper.\nThere are a few things to think about when doing few-shot prompting:\n\n1. How are examples generated?\n2. How many examples are in each prompt?\n3. How are examples selected at runtime?\n4. How are examples formatted in the prompt?\n\nHere are the considerations for each.\n\n## 1. Generating examples\n\nThe first and most important step of few-shot prompting is coming up with a good dataset of examples. Good examples should be relevant at runtime, clear, informative, and provide information that was not already known to the model.\n\nThese requirements are model-specific and should be checked for the model you are using. If your model requires ToolMessages after tool calls and/or AIMessages after ToolMessages and your examples only include expected tool calls and not the actual tool outputs, you can try adding dummy ToolMessages / AIMessages to the end of each example with generic contents to satisfy the API constraints.\nIn these cases it\'s especially worth experimenting with inserting your examples as strings versus messages, as having dummy messages can adversely affect certain models.\n\nYou can see a case study of how Anthropic and OpenAI respond to different few-shot prompting techniques on two different tool calling benchmarks [here](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/).\n\n### Example selectors\n\n[Example Selectors](/docs/concepts/example_selectors) are responsible for selecting the correct few shot examples to pass to the prompt.\n\n- [How to: use example selectors](/docs/how_to/example_selectors)\n- [How to: select examples by length](/docs/how_to/example_selectors_length_based)\n- [How to: select examples by semantic similarity](/docs/how_to/example_selectors_similarity)\n- [How to: select examples by semantic ngram overlap](/docs/how_to/example_selectors_ngram)\n- [How to: select examples by maximal marginal relevance](/docs/how_to/example_selectors_mmr)\n- [How to: select examples from LangSmith few-shot datasets](/docs/how_to/example_selectors_langsmith/)\n\n### LLMs\n\nWhat LangChain calls [LLMs](/docs/concepts/text_llms) are older forms of language models that take a string in and output a string. \nAnswer:', additional_kwargs={}, response_metadata={})]ªfocus_kind¶chain_execution_result†¢idÙ@8fd5c63e39a93433a6a5a6210feb4969b97cd09962e14d52ade056e6b0f1ba92¢tsËAÚşsÊË%¨focus_msÍÖ§payload‚¤role©assistant§contentÚuFew-shot prompting is a technique that enhances model performance by providing examples of desired inputs and outputs within a prompt. It is supported by carefully generating relevant examples, selecting them at runtime, and formatting them appropriately for the model. This approach is based on the principles outlined in the "Language Models are Few-Shot Learners" paper.ªfocus_kind¬exec_latency¨query_id¤Q007‰¢idÙ@2b9c583bad4c453ff3a3ae15448311044f0b82f62fab586bf57357af5f31a3fd¢tsËAÚşsÊİè¨trace_idÙ$ebbc14f6-86f0-41dc-8751-3f7cb8d308e4­parent_run_idÙ$d2c9e0cc-d053-41ef-9e50-8d8ff5dd49c4¦run_idÙ$ebbc14f6-86f0-41dc-8751-3f7cb8d308e4ªevent_type¬chain_output¬event_source¥chain§payload§outputs‚¦answerÚuFew-shot prompting is a technique that enhances model performance by providing examples of desired inputs and outputs within a prompt. It is supported by carefully generating relevant examples, selecting them at runtime, and formatting them appropriately for the model. This approach is based on the principles outlined in the "Language Models are Few-Shot Learners" paper.¨query_id¤Q007ªfocus_kind¶chain_execution_result‹¢idÙ@c0fe210b524d2fbcefb5457f84ab130e2621719331ac7b67ae4885aaec2b4aa4¢tsËAÚşsÊôA¨trace_id¤Q008­parent_run_idÀ¦run_idÙ$9017e9fd-fd27-46e1-b111-acb8b4e5ea75ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ<Give an example of a memory object that stores chat history.¨query_id¤Q008§context¦answer ¯serialized_reprÀ¤tags¨metadata¨query_id¤Q008ªfocus_kind¯chain_execution‹¢idÙ@dae44d0a452b1779c4e07f70b522e928deaeefc367c341db34ad1f39fdae5733¢tsËAÚşsËÎ¨trace_id¤Q008­parent_run_idÙ$9017e9fd-fd27-46e1-b111-acb8b4e5ea75¦run_idÙ$94f98f97-f5e1-4aa1-807d-80e8baf4bdf1ªevent_type«chain_start¬event_source­Unknown Chain§payload‚¦inputs„¨questionÙ<Give an example of a memory object that stores chat history.§context¦answer ¨query_id¤Q008¯serialized_reprÀ¤tags‘¬graph:step:1¨metadata†¨query_id¤Q008®langgraph_step®langgraph_node¨retrieve²langgraph_triggers‘²branch:to:retrieve®langgraph_path’­__pregel_pull¨retrieve·langgraph_checkpoint_nsÙ-retrieve:3f2fcea3-1097-8823-5b44-6aea51b91b36ªfocus_kind¯chain_execution‰¢idÙ@e030b6eec87c7baa2f8968476f987dfb2a0c5f388ce9fc24a579576c048b2a2d¢tsËAÚşsÒÇ¬¨trace_idÙ$94f98f97-f5e1-4aa1-807d-80e8baf4bdf1­parent_run_idÙ$9017e9fd-fd27-46e1-b111-acb8b4e5ea75¦run_idÙ$94f98f97-f5e1-4aa1-807d-80e8baf4bdf1ªevent_type«chain_error¬event_source¥chain§payload¥error ªfocus_kind¥error‰¢idÙ@b164e183136a271c53c83112021bfb48059249d1e1d8b1103b0206cb3f334c9f¢tsËAÚşsÒÍ¯¨trace_idÙ$9017e9fd-fd27-46e1-b111-acb8b4e5ea75­parent_run_idÀ¦run_idÙ$9017e9fd-fd27-46e1-b111-acb8b4e5ea75ªevent_type«chain_error¬event_source¥chain§payload¥error ªfocus_kind¥error